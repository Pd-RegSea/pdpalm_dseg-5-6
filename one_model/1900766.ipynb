{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ! unzip -oq /home/aistudio/data/data85135/常规赛：PALM病理性近视病灶检测与分割.zip\r\n",
    "# ! rm -rf __MACOSX\r\n",
    "# ! mv 常规赛：PALM病理性近视病灶检测与分割 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ! git clone https://gitee.com/paddlepaddle/PaddleSeg.git\r\n",
    "! pip -q install patta\r\n",
    "\r\n",
    "import sys\r\n",
    "\r\n",
    "sys.path.append('PaddleSeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import random\r\n",
    "\r\n",
    "def create_list():\r\n",
    "    file_path = 'dataset/Train/fundus_image'\r\n",
    "    imgs_name = os.listdir(file_path)\r\n",
    "    random.shuffle(imgs_name)\r\n",
    "    with open('dataset/Train/train.txt', 'w') as tf:\r\n",
    "        with open('dataset/Train/val.txt', 'w') as ef:\r\n",
    "            for idx, img_name in enumerate(imgs_name):\r\n",
    "                img_path = os.path.join('fundus_image', img_name)\r\n",
    "                lab_1_path = img_exist('dataset/Train', img_path.replace('fundus_image', 'Lesion_Masks/Detachment').replace('jpg', 'bmp'))\r\n",
    "                lab_2_path = img_exist('dataset/Train', img_path.replace('fundus_image', 'Lesion_Masks/Atrophy').replace('jpg', 'bmp'))\r\n",
    "                if (idx % 10 + 1) < 9:\r\n",
    "                    tf.write(img_path + ' ' + lab_1_path + ' ' + lab_2_path + '\\n')\r\n",
    "                else:\r\n",
    "                    ef.write(img_path + ' ' + lab_1_path + ' ' + lab_2_path + '\\n')\r\n",
    "\r\n",
    "def img_exist(path, name):\r\n",
    "    p = os.path.join(path, name)\r\n",
    "    if os.path.exists(p):\r\n",
    "        return name\r\n",
    "    else:\r\n",
    "        return 'None'\r\n",
    "\r\n",
    "# create_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddleseg.datasets import DBDataset\r\n",
    "import paddleseg.transforms as T\r\n",
    "\r\n",
    "# 构建训练集\r\n",
    "train_transforms = [\r\n",
    "    T.Resize(target_size=(1120, 1120)),  # 修改大小\r\n",
    "    T.Normalize()  # 归一化\r\n",
    "]\r\n",
    "train_dataset = DBDataset(\r\n",
    "    transforms=train_transforms,\r\n",
    "    dataset_root='dataset/Train',\r\n",
    "    num_classes=2,\r\n",
    "    mode='train',\r\n",
    "    train_path='dataset/Train/train.txt',\r\n",
    "    separator=' ',\r\n",
    ")\r\n",
    "\r\n",
    "# 构建验证集\r\n",
    "val_transforms = [\r\n",
    "    T.Resize(target_size=(1120, 1120)),\r\n",
    "    T.Normalize()\r\n",
    "]\r\n",
    "val_dataset = DBDataset(\r\n",
    "    transforms=val_transforms,\r\n",
    "    dataset_root='dataset/Train',\r\n",
    "    num_classes=2,\r\n",
    "    mode='val',\r\n",
    "    val_path='dataset/Train/val.txt',\r\n",
    "    separator=' ',\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1120, 1120) 1 1 (1120, 1120) (1120, 1120)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAACFCAYAAABSfS+4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAGJtJREFUeJztnVmMXNdxQE9Nzz5ch8toRGqNJXmnLNO05CiGHcGkpCy28yFLASLGUcAggX8CBIgMfxhIfuz8xbDhmAGESAG8CEEM8UM2TSmIHcR2JNLWQi8yxxZl7vs2+8Kbj7rF+0jO1tPb6351gEa/uf263+1X01X3VtWtKyEEHMdxnOLR1ugOOI7jOI3BDYDjOE5BcQPgOI5TUNwAOI7jFBQ3AI7jOAXFDYDjOE5BqbsBEJEHReQNERkSkSfrfX2nNrhcWxOXa2sj9VwHICIl4FfAx4DDwMvAYyGEn9etE07Vcbm2Ji7X1qfeM4AtwFAI4TchhEngm8DH69wHp/q4XFsTl2uL017n620ADmX+Pgx8MHuCiOwAdsQ/31+nfjkLczqEsG6O18qSa1+vvP/tb+usSSed8tj32kRFcgWXbR45eGiK02dnZKHz6m0AFiSEsBPYCSAiXqciP7xVyZuzct28qTu8tPumqnTKqYzS4FBFcgWXbR7Zsu3QwidRfxfQESD737ExtjnNjcu1NXG5tjj1NgAvA3eIyG0i0gk8Cuyqcx+c6uNybU1cri1OXV1AIYRpEfkMsBsoAU+FEH5Wzz441cfl2pq4XFufuscAQgjPA8/X+7pObXG5tiYu19bGVwI7juMUFDcAjuM4BcUNgOM4TkFxA+A4jlNQ3AA4juMUFDcAjuM4BcUNgOM4TkFxA+A4jlNQ3AA4juMUFDcAjuM4BSV35aAdp9nZduPdV453H31l1vbFkn2/41QbNwCOs0QWo9CXovQX8343DE41cAPgOGVQqUKvFtf2ww2CsxTcADjOIsmL8p+NudxOjjMfbgAcZwHyrPgdpxI8C8hx5qEZlX8z9tlpDG4AlsBipk2lmvfCqSXbbry7qRVpM/fdqR/uAloC0/O8JsCKeDwMzNS+O06VaRXlue3Gu1syHjCbfFrxe9YDNwBVpB01AH1AJ9APnEINgdMctIrybyXKTbd1Y7B43AVUBbqAZejMYApYBUwAk8AAcBNqFJx804rKv5m/01LdcM3uvqsnbgCqwAQ6yl+HKv+foyP/EXRWMIlPtfKOK4x8UQ15uEwXxg1ABfSgo//lwEbgBuB24D7g3cBa4AhwArjQoD46i6OV3QbNpAirPXpvpu/eCHxgWgFr0RF/d3x0xPYeIKDuoNXAOdQIXGpAHx2nWaiVsm7VYHg18BlABUyjyr4dnQWsQX3+bagxmADGUVfQ5Qb10XGagVqP1H0mMDs+AwBWoq6ck2W+bxI1AgPABlLuf0BdPm1oVlCIDzt2nHrTKqPga7+DK/bKKKwBWA+8C+hFR+9twE+BX5T5OZ2kWUAXOuIvxfYRdCawMj5PAWPxMVnxN3Cc1mAxSnwu47X76CuLNgKtYgSrSSFdQL8XH3fGxwDwa+BtwIeA31nk53SjN9CUf4m0FsAsqx33xuNe1PisrML3cJwisJDSdqW+dApnAN6PBmY3AreiWTqCKv5bgXuAe1GFPh+C+vW7UV//ZXSEX4rv7UNXBJfQGUIvGjA2A2Ezhw6ScXAaiyuS/LFYmbjslkahXEB/iC7YKgE3o4r3Hajyvg9V5AfQm/L7wHfm+awSusBLUMU/iSr1btTPf46k+EFjBe2kOEFnPD4Xr98Xzxmv+Fs6S8X9yfVnvnvuSr32FGYG8AA6Il+OlmjYiCrfjwF/CbwHuDG+thydDczHXWjWzwyqzAVV+H2k9QHEcy6jI/1lpFF/N2l2sDa+r4+FZx6O48yOG4zyKcQMoBO4iLp++lBF/BbwCdQfD6qUL6LKvzeeW2L2Ym5r0ayfFehMYgZV5OYWCvGavfG1Deg6gIl47fHY3h/PG0Yt8XR8fw8aKHacouLKvD4UwgDcj474V6FKuh8YREfn7e0wU4KZCX1tLJ7TxvXKvxtV6jfH966Kz8OoUu8m+fdXoYZgAl0AtgadcQiq6DtQt5Gdd57kLhqP1/e1A47j1JJCuIC6UMVbQhX8aVS5dwFTHdA2ocrW8vYFVc7dwPvQEf/bgLtJwdtSPGc8fo6tAjb3zmXUugZ01G8F47rjebZy2NxDXahh6CRlFDlOK1PvmIvPKq6nEAYgkEbzl9EFX2+gGUCdY/r6MOqmuYyO1o+gyv2n6Mj8IrAfXeDVE8+7jCrrbpLf/yx6U0uoYjeDYoYjxPMtdbQt/t0fn0fiOfPtOeBUnyIEgJvlO7qirh+FMACvAr9CM3xOoDn/JdTfP92TjMI5VMGX4jnGMtRlNIy6ktahxmEtGkNYhSrzzvj3KZK7yNxOtkagl5QtBCqATrQPJXR9QCm+z3GcxdMsBi5PVBQDEJGDqIt7BpgOIWwWkX7gW2gizUHgkRDCORER4J+Bh4FR4M9DCD+p5PqLYQOwCVXWK4DfAh9FF4CtBkbHUsXOs6ji/V9UQT8Qzz8azwU1EpNo1c9bSYHiFaSMoA1oauj5+J4ekqvI3DyWNnoWNTBmJHpRozBB7oLBJRHZQ07kWk2KpDhu/8BBli9ro1SC9pKuPsnbb9apH9WYAXw0hHB3CGFz/PtJ4MUQwh3Ai/FvgIeAO+JjB/DVKlx7QY6givkyqrxLqBLuB4bQWcFbaFxgPLZ3oWUi3gP8Lmol70RnDHeRCSCjbp7samBILqCVpDpAlvaZTQedRGcMFvBtJ6WUdqBGxWYKOWCQHMnVWTov/scGfvLCzby0+yZrytVvtha4W2l2auEC+jjwdDx+Gs22tPZngvJjYJWIDNbg+tdh2T3n0JnAFHAYrftzkDT6X42O9n8OfAX4H+Dr6PqA/cAH0ZH/JlLVz1LmYQFgMwTtaNppibROwIyFuXkukVYUW+ZR1v9vC8ZywCpyJtdqUKTR/zzk6je71F3AnPKp1AAE4Hsisk9EdsS2gRDCsXh8HNWVoJ6RQ5n3Ho5tVyEiO0Rkr4jsrbBvV7C0SlAlfABV9GdR5X8OVdTHgf8E/gudCexDDcZrwDG0XMT9pFo+y+MjWwuoM/PcTsr2scCxKfq22K+VpFTRS2gMYjieO53pdw5KRbRXS66nzsy2usKpByLw4KNH+cDWQ+z89yvbFFXtN1uObKs1Kl9I+fvof24qXQdwfwjhiIisB/aIyC+zL4YQgoiUVQE5hLAT2AlQ7nvn4r/RoQzAS2gQ9zQ6K+hCh7ZTaGbQ99CUT9Cb807UWKxFR+e3xfdcQBX7OOq3n4jnT6FK3raBnESV/CRJqVvKaQ+q9PtQBT+DWtQe1OF6Mb4225qERlKpXDdv6s5FVewijhp/8NxGNgy2c/L0NNs+dRTUI3mFesu2nGqes1FEGVaTimYAIYQj8fkk8G1gC3DCponx2crsH0HL5xgbY1td+CGqUEdRZ/Yv4t8r0F/AvwL/AmxFg7dD8bU+4CNobaAB1BAsi+1W49/cOkJaA9AXnzvj62Mk108naghK8fw+1Jh0kNxJXZnrT5FSShvIdB7lulSKqjg2DOqYb/3adj7xUB/ov1hDf7OzjdAXI5+iyrCaLNkAiEifiCy3Y1R37gd2AdvjaduB5+LxLuBxUe4FLmSmnTXnFPA6GvAdQmcBrwMvAJ9D8+9BZwCb4vEqVOH/GfAHaCVRc+VYENdG9lk/vcUGVpHcPbYYrJMU4O3IvK+H5FKyEtJ2bEagwcPm8+RQrs7imQnTPDD4LgBGRi+z5/tjoGOThv9m5zICcyn5xSp/d//MTyUuoAHg25opRjvw9RDCd0XkZeBZEXkC1bePxPOfR9PJhtCB+KcruPaSMI/nEBroPU5K78zm/dtNWYHGC0rA36BfeCK+ZovGrPZPd+bYZgZmKKxtBnUXTcfzx0luI7PEFhTuIG0e05H5nAZWCz0GfCyPci2Xoo4cJxjnNX7E+x4YY3oaHvvkMn60d/wi8AVy8Judyx1UVHnVAwkhF+7YWalWDGAhVpIU742okj+D5r7dAnwSDf7aiP4YGkAeJhkEcwOZjz/r858h7QZ2EZ1tjMVrSPwsO28M/aUJquwvx+fReJ1pGrY2YF8m1bciNm/qDpkUxLriyuTqUXFpcKhqcoXqyLZaMiry6H/LtkPsfXV8Qa9xIYrBzcVtwJukmYGlch5FnZ1dqEF4B+rCsRVvw6gSt5G7lYQwa2U5/dn6QhYDmEKV+AQ6CzDDY0HeKdTlc5Gr1wdYtdAcZAM5Tk0xxb1UQ1BkxV8uhTMAtjcvqBK/Ey0TAervH4iv34X6629H4wclUnXPcZKfvi3zgOS+sUJvoySXzzTqAmqP155ER/+m/EN8ny1cm0ENgaWUmrBsNtDK+EjdKTdDyBV/+RTOAEyhyjugqQ5TmdcseHsrmilkmTe2T8A0qrQD6jY6R8r7N4XdRlL+tlLYfPgjsf0SKbXTSkiPocbFSkv0xmutQGcctiZguIr3wnHyTlapz2UMXPEvncIZAEiF4Ex534Aq3QNozlsbqqwHUCW/AnULLSPl+58i5e5bho4ZAgsK2ybwgrqIutDRuxma1bFtgpROeokURM6mmEJat2C1ghynSLiirz6FMwDZQmxtqILuyzwOoHn/y1FFbCWezf3TTtpLwIK+HSR3UB/J/29ttmr4KLqZzJvxPWtIpZ/NgNjisnZU4VscwWIJFmRuZdz94zj1oXAGYDI+X0S/vFXi7ECVcx/wMroRzGpS+eZxNFhs+/b2krJxbCVvL6qcbcRfIpWSNnfQC6QVv1PxnLZ4vpWA6CAp+pl47el4vmUWOY7jVEoh9gOYjTF0VN6DKnjbx/dO4E9QRft9YC+qgC1AO4W6cU6iCjubtmm1fCzv31b+WvZQL1pI5SHU7VTKfN4IKcPHsoQsVgGpoFyeSkI4zYnPsByjcDMAU6r98W+bEdjGLOb2eTtaE+gX6GqYD5EqgF5ElXmJ5Bay2j8W7DXDYorcAsq3oMXlbF8By/WfRI3JJGmkP0MKOk+RZg6tiismx6kvhTMAtkdvH1rV08o1mysIVClbTZ73ojUQ9gEfRhW5FX+zvYZtoZaVe+6JnzNByhQ6Gj/nTZKiP4vODobj39OocZkhrSSeIaWetjKu/B2n/hTOAEDanrELDdCuQpU6qCGwMs7T8bEiPg6iWUKm7C0Tx2IE2RhABzoTGEWVvFX3NAU/gir+8/FhRiA7KzAss6hVceXvOI2hkAZglOSDtw3bu0n1fCwIa0ZiDF0N/BKaudOJKu0Q/7Zzh0mbvJ8hLQKbjK8No66cKXT0P5Y5x0o+2EjfSkO0esaP4ziNo5AGwHzs5vKxtNBpUnF0K9swQXLP9KNK2/L4J1FDYK6faTSwPEZaYGY+/VHUHTSGBorPojttmGEY5epaQh7sdRyn1hQyC8hKOmd97RfREb2N4ofR0fgkKUB8M1oF9BLX5+PbiN0ygUbi8SlU2Z+Jf5+J1zpLKgpnq3utvlDRlL8v8HGcxlDIGUA7msa5Hh3h2+IwK8OQ3YrR3ESW5bMe3U3M0jpHSNlA9llWwtlcP5Oo0j8dzz+DGpcpdFbgK3udeuIG1zEKaQBAN4Sx4KqtvM2WYLDibx3xfCvvbOUclpH891b7pyO2lTKvzaAzAgvuWsZQtsRzth6R4zhOvSicATB3Tgda9uE9pJW14/G1LlLOvY3Ms3v59pP2CbZaPpfQTCFzH03Ea1xCZwTmXroYP8dmBq2c3ePkDx/9O1kKZwBsZH8ZTQE9iwZurX4PqFvG3ED2sBIMXaSFW2fRchG2L8AIaWHYCCnGMB7bre6PxRYu41k+juM0jsIFgadQ5TuKjtjfJPniT6JK/TzqtrHR+wV05G7Pw6iSHwJ+jPr0J1ClPx0/w4yElXIej8eW2mnlHhzFR6a1x++xcy2FmwFAWnHbh47KL5HKNdsovoe0RWMbaROYQErZvDl+zgF0PcAgqfQD8dhy/S0+YK6gbG0hx3GcRlBIA2DF3Y6hs4BfopvACKr4BVXetgWjKX5z77Rn2trRWMAw8BN0C0lbGWyBXzMgtp+vBZ99e0enXvjo35mNQhoASD55q+F/EI0J9HL1Jiy29eNkfI/V+rFKnqClJLpQY7IfNSaQ/Px2bIHly/jI33GcxlNYAwCp9o6lel4gpYRa9c7sNo8W6LXFYdZ+gZQhtA5d4dtPWmQ2TUoLBa/n79QXH/07c1FoA2BkR+O2oAvSwrAsdsP6SBH0cdQQ2AKwUdLWjaPx822BmDM35W4C7jhOZbgBmIfZSjLY6P1CfO4h+fPb0Qwi0KyiLtL6gVEcp/746N+Zj8KlgVabMXQGMIZmE2WZoPU3cak2rrAcp364AXCcFsWNqbMQbgCc3OGKy3HqgxsAJ5e4EagMv3/OYnAD4OQWV2JLw++bs1jcADiO4xQUNwBOrvHRbHn4/XLKwQ2Ak3tcqTlObXAD4DgtghtKp1zcADhNgSu3udl99BW/P86ScAPgNA2u5K7H74lTCQsaABF5SkROisj+TFu/iOwRkQPxeXVsFxH5kogMichrInJP5j3b4/kHRGR7bb6OU0NuyoNcXeEl5roXT/ztCW5495u89yO/vdJ29twMWz91hLs+9BZbP3WEc+dTpSv/zRaXxcwA/g148Jq2J4EXQwh3AC/GvwEeAu6Ijx3AV0ENBvB54IPAFuDzZjScpqGbnMi16EZgIZfP9kdW8PzXB69q++KXz/HA/b288cNbeOD+Xr745XP20kr8N1tYFjQAIYQfoNvcZvk48HQ8fhr4RKb9maD8GFglIoPANmBPCOFsCOEcsIfrjYqTb87kSa5FNQKL+d4fvq+H/tWlq9p27R7h8UeWA/D4I8t57rsj9tIq/DdbWJYaAxgIIRyLx8eBgXi8Ad0PxTgc2+Zqvw4R2SEie0Vk7xL75tSGycxxRXI9dWa2QtvlUyQjUGmg98SpGQYHtPr7DetLnDh1RQYdVPE3Wy3ZOvWh4iBwCCFQxYrHIYSdIYTNIYTN1fpMp/Fk5bpuTWnhNyySIhiBan9HEUGquCF1rWTr1J6lGoATcZpIfD4Z248AN2XO2xjb5mp3mofOzHGu5NqqaZDV/F4D60ocO6HbGR07Mc36tVcU9RT+my0sSzUAuwDLCtgOPJdpfzxmA90LXIiuot3AVhFZHQNJW2Ob0zysybtcTWG2gjGo9nf4o619PPOsbln0zLOX+ONtffbSefw3W1gW3BJSRL4BfARYKyKH0cyALwDPisgTwFvAI/H054GHgSF0F8RPA4QQzorIPwIvx/P+IYRwbWDZyTcTNJFcswq02fYZrlT5/+lfH+f7Pxzj9NkZbr7nTT7/d2v4+8+s5tG/Os5T37jILRvb+ebXbrDTLwC/oYlk61QPURd+PhGR/HaueOyrVlxm86bu8NLumxY+sQbk1Rg0atZSGhyqmlyhsbJ1Elu2HWLvq+MLRnp8U3inUORlZtAKbiqn+XED4BSWa5VwPQyCK34nT7gBcJzIbMq5HKPgyt1pNtwAOM48uFJ3WhmvBuo4jlNQ8p4FdAl4o9H9KIO1wOlGd6IMyunvLSGEddW4qIicAkbKuHajcbkuEv/N1pzF9ndRcs27C+iNZioJISJ7vb8LE0JY10z3qpn6Cg3vr/9ma0i1++suIMdxnILiBsBxHKeg5N0A7Gx0B8rE+9sc1y6XZuoruFzLodD9zXUQ2HEcx6kdeZ8BOI7jODXCDYDjOE5Bya0BEJEHReQNERkSkScXfkd9EJGDIvK6iLxi21aKSL+I7BGRA/F5dWwXEflS/A6vicg9dejfUyJyUkT2Z9rK7p+IbI/nHxCR7bNda4n9c7kurX8u1yXgcl2AEELuHkAJ+DVwO7oT1avAOxvdr9i3g8Daa9r+CXgyHj8JfDEePwx8BxDgXuD/6tC/DwP3APuX2j+gH60R3w+sjserXa4uV5dra8m14QKa46bcB+zO/P1Z4LON7tc8/1BvAIPxeBBdDAPwNeCx2c6rcR9vveYfqqz+AY8BX8u0X3Wey9Xl6nJtDbnm1QW0ATiU+ftwbMsDAfieiOwTkR2xbSDoNnoAx4GBeJyX71Fu/2rV77zcj9lwuS6dvNyP2XC5zkPeS0HkkftDCEdEZD2wR0R+mX0xhBAkxzuZ5b1/DcTl2pq4XOchrzOAI0B2X7mNsa3hhBCOxOeTwLeBLcAJERkEiM8n4+l5+R7l9q9W/c7L/bgOl2tF5OV+XIfLdX7yagBeBu4QkdtEpBN4FNjV4D4hIn0istyOga3AfrRvFnnfDjwXj3cBj8fo/b3AhczUrp6U27/dwFYRWR0zELbGtkpxuVYXl+s8uFwXQaODNPMERh4GfoVmF3yu0f2JfbodzXB4FfiZ9QtYA7wIHABeAPpjuwBfid/hdWBzHfr4DeAYMIX6Ap9YSv+AvwCG4uPTLleXq8u19eTqpSAcx3EKSl5dQI7jOE6NcQPgOI5TUNwAOI7jFBQ3AI7jOAXFDYDjOE5BcQPgOI5TUNwAOI7jFJT/B0tQq3iGcO9sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "import matplotlib\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "for img, clas_1, clas_2, lab_1, lab_2 in train_dataset:\r\n",
    "    if np.min(lab_1) == 0 and np.min(lab_2) == 0:\r\n",
    "        print(img.shape, clas_1, clas_2, lab_1.shape, lab_2.shape)\r\n",
    "        plt.subplot(131);plt.imshow(img.transpose((1, 2, 0)))\r\n",
    "        plt.subplot(132);plt.imshow(lab_1)\r\n",
    "        plt.subplot(133);plt.imshow(lab_2)\r\n",
    "        plt.show()\r\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-22 12:18:43 [INFO]\tLoading pretrained model from save_output/last_model/model.pdparams\n",
      "2021-05-22 12:18:44 [INFO]\tThere are 356/356 variables loaded into DBAttentionUNet.\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "from paddleseg.models import DBAttentionUNet\r\n",
    "from paddleseg.models.losses import BCELoss, DiceLoss, MixedLoss\r\n",
    "from paddle.nn import CrossEntropyLoss\r\n",
    "\r\n",
    "# 模型\r\n",
    "url = 'save_output/last_model/model.pdparams'\r\n",
    "model = DBAttentionUNet(num_classes=2, pretrained=url)\r\n",
    "# 测试\r\n",
    "# a = paddle.randn(shape=[1, 3, 1120, 1120])\r\n",
    "# c = model(a)\r\n",
    "# print(c)\r\n",
    "# 训练参数\r\n",
    "epochs = 10\r\n",
    "batch_size = 2\r\n",
    "iters = epochs * len(train_dataset) // batch_size\r\n",
    "# 损失函数\r\n",
    "mix_losses = [BCELoss('dynamic', 'dynamic'), DiceLoss()]\r\n",
    "mix_coef = [1, 1]\r\n",
    "mixloss = MixedLoss(mix_losses, mix_coef)\r\n",
    "losses = {}\r\n",
    "losses['types'] = [CrossEntropyLoss(), CrossEntropyLoss(), mixloss, mixloss]\r\n",
    "losses['coef'] = [0, 0, 1, 1]\r\n",
    "# 学习率及优化器\r\n",
    "base_lr = 3e-4\r\n",
    "# lr = paddle.optimizer.lr.CosineAnnealingDecay(base_lr, T_max=(iters // 5))\r\n",
    "lr = paddle.optimizer.lr.PolynomialDecay(base_lr, 4277, end_lr=3e-8)\r\n",
    "optimizer = paddle.optimizer.Adam(lr, parameters=model.parameters(), weight_decay=paddle.regularizer.L2Decay(1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py:89: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if isinstance(slot[0], (np.ndarray, np.bool, numbers.Number)):\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:648: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:238: UserWarning: The dtype of left and right variables are not the same, left dtype is VarType.FP32, but right dtype is VarType.BOOL, the right dtype will convert to VarType.FP32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-22 12:18:57 [INFO]\t[TRAIN] epoch=1, iter=10/3200, loss=0.9555, lr=0.000299, batch_cost=1.1094, reader_cost=0.06593, ips=1.8027 samples/sec | ETA 00:58:59\n",
      "2021-05-22 12:19:08 [INFO]\t[TRAIN] epoch=1, iter=20/3200, loss=0.8839, lr=0.000299, batch_cost=1.0351, reader_cost=0.00021, ips=1.9321 samples/sec | ETA 00:54:51\n",
      "2021-05-22 12:19:18 [INFO]\t[TRAIN] epoch=1, iter=30/3200, loss=0.9945, lr=0.000298, batch_cost=1.0359, reader_cost=0.00029, ips=1.9308 samples/sec | ETA 00:54:43\n",
      "2021-05-22 12:19:28 [INFO]\t[TRAIN] epoch=1, iter=40/3200, loss=0.9221, lr=0.000297, batch_cost=1.0367, reader_cost=0.00025, ips=1.9292 samples/sec | ETA 00:54:36\n",
      "2021-05-22 12:19:39 [INFO]\t[TRAIN] epoch=1, iter=50/3200, loss=0.8302, lr=0.000297, batch_cost=1.0375, reader_cost=0.00029, ips=1.9277 samples/sec | ETA 00:54:28\n",
      "2021-05-22 12:19:49 [INFO]\t[TRAIN] epoch=1, iter=60/3200, loss=0.9371, lr=0.000296, batch_cost=1.0380, reader_cost=0.00022, ips=1.9267 samples/sec | ETA 00:54:19\n",
      "2021-05-22 12:20:00 [INFO]\t[TRAIN] epoch=1, iter=70/3200, loss=0.8121, lr=0.000295, batch_cost=1.0415, reader_cost=0.00028, ips=1.9203 samples/sec | ETA 00:54:19\n",
      "2021-05-22 12:20:10 [INFO]\t[TRAIN] epoch=1, iter=80/3200, loss=1.0420, lr=0.000294, batch_cost=1.0385, reader_cost=0.00021, ips=1.9259 samples/sec | ETA 00:54:00\n",
      "2021-05-22 12:20:20 [INFO]\t[TRAIN] epoch=1, iter=90/3200, loss=0.9464, lr=0.000294, batch_cost=1.0394, reader_cost=0.00030, ips=1.9241 samples/sec | ETA 00:53:52\n",
      "2021-05-22 12:20:31 [INFO]\t[TRAIN] epoch=1, iter=100/3200, loss=1.3010, lr=0.000293, batch_cost=1.0403, reader_cost=0.00020, ips=1.9226 samples/sec | ETA 00:53:44\n",
      "2021-05-22 12:20:41 [INFO]\t[TRAIN] epoch=1, iter=110/3200, loss=0.8998, lr=0.000292, batch_cost=1.0403, reader_cost=0.00025, ips=1.9224 samples/sec | ETA 00:53:34\n",
      "2021-05-22 12:20:52 [INFO]\t[TRAIN] epoch=1, iter=120/3200, loss=0.8575, lr=0.000292, batch_cost=1.0405, reader_cost=0.00023, ips=1.9222 samples/sec | ETA 00:53:24\n",
      "2021-05-22 12:21:02 [INFO]\t[TRAIN] epoch=1, iter=130/3200, loss=0.8689, lr=0.000291, batch_cost=1.0404, reader_cost=0.00019, ips=1.9224 samples/sec | ETA 00:53:13\n",
      "2021-05-22 12:21:12 [INFO]\t[TRAIN] epoch=1, iter=140/3200, loss=1.0753, lr=0.000290, batch_cost=1.0411, reader_cost=0.00020, ips=1.9211 samples/sec | ETA 00:53:05\n",
      "2021-05-22 12:21:23 [INFO]\t[TRAIN] epoch=1, iter=150/3200, loss=0.7902, lr=0.000290, batch_cost=1.0410, reader_cost=0.00019, ips=1.9212 samples/sec | ETA 00:52:55\n",
      "2021-05-22 12:21:33 [INFO]\t[TRAIN] epoch=1, iter=160/3200, loss=1.1107, lr=0.000289, batch_cost=1.0421, reader_cost=0.00017, ips=1.9192 samples/sec | ETA 00:52:48\n",
      "2021-05-22 12:21:44 [INFO]\t[TRAIN] epoch=1, iter=170/3200, loss=0.8725, lr=0.000288, batch_cost=1.0424, reader_cost=0.00018, ips=1.9187 samples/sec | ETA 00:52:38\n",
      "2021-05-22 12:21:54 [INFO]\t[TRAIN] epoch=1, iter=180/3200, loss=0.8248, lr=0.000287, batch_cost=1.0420, reader_cost=0.00020, ips=1.9194 samples/sec | ETA 00:52:26\n",
      "2021-05-22 12:22:04 [INFO]\t[TRAIN] epoch=1, iter=190/3200, loss=0.8273, lr=0.000287, batch_cost=1.0423, reader_cost=0.00022, ips=1.9188 samples/sec | ETA 00:52:17\n",
      "2021-05-22 12:22:15 [INFO]\t[TRAIN] epoch=1, iter=200/3200, loss=1.0608, lr=0.000286, batch_cost=1.0419, reader_cost=0.00017, ips=1.9196 samples/sec | ETA 00:52:05\n",
      "2021-05-22 12:22:25 [INFO]\t[TRAIN] epoch=1, iter=210/3200, loss=0.9088, lr=0.000285, batch_cost=1.0431, reader_cost=0.00020, ips=1.9174 samples/sec | ETA 00:51:58\n",
      "2021-05-22 12:22:36 [INFO]\t[TRAIN] epoch=1, iter=220/3200, loss=0.8139, lr=0.000285, batch_cost=1.0428, reader_cost=0.00020, ips=1.9178 samples/sec | ETA 00:51:47\n",
      "2021-05-22 12:22:46 [INFO]\t[TRAIN] epoch=1, iter=230/3200, loss=0.7854, lr=0.000284, batch_cost=1.0433, reader_cost=0.00022, ips=1.9170 samples/sec | ETA 00:51:38\n",
      "2021-05-22 12:22:57 [INFO]\t[TRAIN] epoch=1, iter=240/3200, loss=0.8519, lr=0.000283, batch_cost=1.0428, reader_cost=0.00020, ips=1.9178 samples/sec | ETA 00:51:26\n",
      "2021-05-22 12:23:07 [INFO]\t[TRAIN] epoch=1, iter=250/3200, loss=0.8112, lr=0.000283, batch_cost=1.0434, reader_cost=0.00018, ips=1.9169 samples/sec | ETA 00:51:17\n",
      "2021-05-22 12:23:17 [INFO]\t[TRAIN] epoch=1, iter=260/3200, loss=0.8087, lr=0.000282, batch_cost=1.0439, reader_cost=0.00020, ips=1.9158 samples/sec | ETA 00:51:09\n",
      "2021-05-22 12:23:28 [INFO]\t[TRAIN] epoch=1, iter=270/3200, loss=0.9894, lr=0.000281, batch_cost=1.0435, reader_cost=0.00022, ips=1.9167 samples/sec | ETA 00:50:57\n",
      "2021-05-22 12:23:38 [INFO]\t[TRAIN] epoch=1, iter=280/3200, loss=1.1612, lr=0.000280, batch_cost=1.0505, reader_cost=0.00025, ips=1.9038 samples/sec | ETA 00:51:07\n",
      "2021-05-22 12:23:49 [INFO]\t[TRAIN] epoch=1, iter=290/3200, loss=0.9393, lr=0.000280, batch_cost=1.0435, reader_cost=0.00028, ips=1.9165 samples/sec | ETA 00:50:36\n",
      "2021-05-22 12:23:59 [INFO]\t[TRAIN] epoch=1, iter=300/3200, loss=0.8348, lr=0.000279, batch_cost=1.0446, reader_cost=0.00019, ips=1.9146 samples/sec | ETA 00:50:29\n",
      "2021-05-22 12:24:10 [INFO]\t[TRAIN] epoch=1, iter=310/3200, loss=0.8331, lr=0.000278, batch_cost=1.0441, reader_cost=0.00023, ips=1.9156 samples/sec | ETA 00:50:17\n",
      "2021-05-22 12:24:20 [INFO]\t[TRAIN] epoch=1, iter=320/3200, loss=0.7918, lr=0.000278, batch_cost=1.0436, reader_cost=0.00025, ips=1.9164 samples/sec | ETA 00:50:05\n",
      "2021-05-22 12:24:20 [INFO]\tStart evaluating (total_samples=160, total_iters=160)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:238: UserWarning: The dtype of left and right variables are not the same, left dtype is VarType.INT32, but right dtype is VarType.BOOL, the right dtype will convert to VarType.INT32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:238: UserWarning: The dtype of left and right variables are not the same, left dtype is VarType.INT64, but right dtype is VarType.BOOL, the right dtype will convert to VarType.INT64\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "160/160 [==============================] - 52s 322ms/step - batch_cost: 0.1608 - reader cost: 0.141\n",
      "160/160 [==============================] - 52s 322ms/step - batch_cost: 0.1603 - reader cost: 0.1405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-22 12:25:12 [INFO]\t[EVAL] #Images=160 mIoU=0.4941 Acc=0.9881 Kappa=0.0000 \n",
      "2021-05-22 12:25:12 [INFO]\t[EVAL] Class IoU: \n",
      "[0.     0.9881]\n",
      "2021-05-22 12:25:12 [INFO]\t[EVAL] Class Acc: \n",
      "[0.     0.9881]\n",
      "2021-05-22 12:25:12 [INFO]\t[EVAL] #Images=160 mIoU=0.6922 Acc=0.9518 Kappa=0.5821 \n",
      "2021-05-22 12:25:12 [INFO]\t[EVAL] Class IoU: \n",
      "[0.4344 0.95  ]\n",
      "2021-05-22 12:25:12 [INFO]\t[EVAL] Class Acc: \n",
      "[0.8396 0.957 ]\n",
      "2021-05-22 12:25:16 [INFO]\t[EVAL] The model with the best validation mIoU (0.6922) was saved at iter 320.\n",
      "2021-05-22 12:25:27 [INFO]\t[TRAIN] epoch=2, iter=330/3200, loss=0.8551, lr=0.000277, batch_cost=1.1219, reader_cost=0.07269, ips=1.7827 samples/sec | ETA 00:53:39\n",
      "2021-05-22 12:25:38 [INFO]\t[TRAIN] epoch=2, iter=340/3200, loss=0.8675, lr=0.000276, batch_cost=1.0416, reader_cost=0.00019, ips=1.9201 samples/sec | ETA 00:49:38\n",
      "2021-05-22 12:25:48 [INFO]\t[TRAIN] epoch=2, iter=350/3200, loss=1.0384, lr=0.000276, batch_cost=1.0421, reader_cost=0.00020, ips=1.9192 samples/sec | ETA 00:49:30\n",
      "2021-05-22 12:25:59 [INFO]\t[TRAIN] epoch=2, iter=360/3200, loss=0.9116, lr=0.000275, batch_cost=1.0423, reader_cost=0.00020, ips=1.9188 samples/sec | ETA 00:49:20\n",
      "2021-05-22 12:26:09 [INFO]\t[TRAIN] epoch=2, iter=370/3200, loss=0.9134, lr=0.000274, batch_cost=1.0430, reader_cost=0.00020, ips=1.9175 samples/sec | ETA 00:49:11\n",
      "2021-05-22 12:26:20 [INFO]\t[TRAIN] epoch=2, iter=380/3200, loss=0.8006, lr=0.000273, batch_cost=1.0424, reader_cost=0.00021, ips=1.9187 samples/sec | ETA 00:48:59\n",
      "2021-05-22 12:26:30 [INFO]\t[TRAIN] epoch=2, iter=390/3200, loss=0.7854, lr=0.000273, batch_cost=1.0431, reader_cost=0.00021, ips=1.9174 samples/sec | ETA 00:48:51\n",
      "2021-05-22 12:26:40 [INFO]\t[TRAIN] epoch=2, iter=400/3200, loss=0.7931, lr=0.000272, batch_cost=1.0420, reader_cost=0.00021, ips=1.9195 samples/sec | ETA 00:48:37\n",
      "2021-05-22 12:26:51 [INFO]\t[TRAIN] epoch=2, iter=410/3200, loss=0.8416, lr=0.000271, batch_cost=1.0430, reader_cost=0.00020, ips=1.9175 samples/sec | ETA 00:48:29\n",
      "2021-05-22 12:27:01 [INFO]\t[TRAIN] epoch=2, iter=420/3200, loss=1.0888, lr=0.000271, batch_cost=1.0420, reader_cost=0.00018, ips=1.9194 samples/sec | ETA 00:48:16\n",
      "2021-05-22 12:27:12 [INFO]\t[TRAIN] epoch=2, iter=430/3200, loss=0.8633, lr=0.000270, batch_cost=1.0435, reader_cost=0.00021, ips=1.9166 samples/sec | ETA 00:48:10\n",
      "2021-05-22 12:27:22 [INFO]\t[TRAIN] epoch=2, iter=440/3200, loss=0.8411, lr=0.000269, batch_cost=1.0437, reader_cost=0.00020, ips=1.9163 samples/sec | ETA 00:48:00\n",
      "2021-05-22 12:27:33 [INFO]\t[TRAIN] epoch=2, iter=450/3200, loss=1.0639, lr=0.000269, batch_cost=1.0438, reader_cost=0.00028, ips=1.9160 samples/sec | ETA 00:47:50\n",
      "2021-05-22 12:27:43 [INFO]\t[TRAIN] epoch=2, iter=460/3200, loss=0.9348, lr=0.000268, batch_cost=1.0432, reader_cost=0.00021, ips=1.9171 samples/sec | ETA 00:47:38\n",
      "2021-05-22 12:27:53 [INFO]\t[TRAIN] epoch=2, iter=470/3200, loss=0.9230, lr=0.000267, batch_cost=1.0447, reader_cost=0.00022, ips=1.9144 samples/sec | ETA 00:47:32\n",
      "2021-05-22 12:28:04 [INFO]\t[TRAIN] epoch=2, iter=480/3200, loss=0.8812, lr=0.000266, batch_cost=1.0436, reader_cost=0.00022, ips=1.9164 samples/sec | ETA 00:47:18\n",
      "2021-05-22 12:28:14 [INFO]\t[TRAIN] epoch=2, iter=490/3200, loss=0.8371, lr=0.000266, batch_cost=1.0502, reader_cost=0.00020, ips=1.9044 samples/sec | ETA 00:47:26\n",
      "2021-05-22 12:28:25 [INFO]\t[TRAIN] epoch=2, iter=500/3200, loss=0.8001, lr=0.000265, batch_cost=1.0440, reader_cost=0.00021, ips=1.9158 samples/sec | ETA 00:46:58\n",
      "2021-05-22 12:28:35 [INFO]\t[TRAIN] epoch=2, iter=510/3200, loss=0.8790, lr=0.000264, batch_cost=1.0441, reader_cost=0.00022, ips=1.9155 samples/sec | ETA 00:46:48\n",
      "2021-05-22 12:28:46 [INFO]\t[TRAIN] epoch=2, iter=520/3200, loss=0.9014, lr=0.000264, batch_cost=1.0446, reader_cost=0.00023, ips=1.9147 samples/sec | ETA 00:46:39\n",
      "2021-05-22 12:28:56 [INFO]\t[TRAIN] epoch=2, iter=530/3200, loss=0.8508, lr=0.000263, batch_cost=1.0451, reader_cost=0.00022, ips=1.9137 samples/sec | ETA 00:46:30\n",
      "2021-05-22 12:29:07 [INFO]\t[TRAIN] epoch=2, iter=540/3200, loss=0.8715, lr=0.000262, batch_cost=1.0449, reader_cost=0.00025, ips=1.9140 samples/sec | ETA 00:46:19\n",
      "2021-05-22 12:29:17 [INFO]\t[TRAIN] epoch=2, iter=550/3200, loss=1.3711, lr=0.000261, batch_cost=1.0433, reader_cost=0.00020, ips=1.9170 samples/sec | ETA 00:46:04\n",
      "2021-05-22 12:29:28 [INFO]\t[TRAIN] epoch=2, iter=560/3200, loss=0.7738, lr=0.000261, batch_cost=1.0438, reader_cost=0.00022, ips=1.9160 samples/sec | ETA 00:45:55\n",
      "2021-05-22 12:29:38 [INFO]\t[TRAIN] epoch=2, iter=570/3200, loss=0.8568, lr=0.000260, batch_cost=1.0440, reader_cost=0.00020, ips=1.9157 samples/sec | ETA 00:45:45\n",
      "2021-05-22 12:29:48 [INFO]\t[TRAIN] epoch=2, iter=580/3200, loss=1.0253, lr=0.000259, batch_cost=1.0433, reader_cost=0.00021, ips=1.9171 samples/sec | ETA 00:45:33\n",
      "2021-05-22 12:29:59 [INFO]\t[TRAIN] epoch=2, iter=590/3200, loss=0.8156, lr=0.000259, batch_cost=1.0442, reader_cost=0.00020, ips=1.9154 samples/sec | ETA 00:45:25\n",
      "2021-05-22 12:30:09 [INFO]\t[TRAIN] epoch=2, iter=600/3200, loss=0.8451, lr=0.000258, batch_cost=1.0436, reader_cost=0.00021, ips=1.9164 samples/sec | ETA 00:45:13\n",
      "2021-05-22 12:30:20 [INFO]\t[TRAIN] epoch=2, iter=610/3200, loss=0.8675, lr=0.000257, batch_cost=1.0421, reader_cost=0.00021, ips=1.9193 samples/sec | ETA 00:44:58\n",
      "2021-05-22 12:30:30 [INFO]\t[TRAIN] epoch=2, iter=620/3200, loss=1.0129, lr=0.000257, batch_cost=1.0423, reader_cost=0.00023, ips=1.9189 samples/sec | ETA 00:44:49\n",
      "2021-05-22 12:30:41 [INFO]\t[TRAIN] epoch=2, iter=630/3200, loss=1.0868, lr=0.000256, batch_cost=1.0422, reader_cost=0.00021, ips=1.9190 samples/sec | ETA 00:44:38\n",
      "2021-05-22 12:30:51 [INFO]\t[TRAIN] epoch=2, iter=640/3200, loss=0.7938, lr=0.000255, batch_cost=1.0431, reader_cost=0.00021, ips=1.9173 samples/sec | ETA 00:44:30\n",
      "2021-05-22 12:30:51 [INFO]\tStart evaluating (total_samples=160, total_iters=160)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 53s 328ms/step - batch_cost: 0.1640 - reader cost: 0.142\n",
      "160/160 [==============================] - 53s 328ms/step - batch_cost: 0.1634 - reader cost: 0.1425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-22 12:31:44 [INFO]\t[EVAL] #Images=160 mIoU=0.4941 Acc=0.9881 Kappa=0.0000 \n",
      "2021-05-22 12:31:44 [INFO]\t[EVAL] Class IoU: \n",
      "[0.     0.9881]\n",
      "2021-05-22 12:31:44 [INFO]\t[EVAL] Class Acc: \n",
      "[0.     0.9881]\n",
      "2021-05-22 12:31:44 [INFO]\t[EVAL] #Images=160 mIoU=0.7265 Acc=0.9561 Kappa=0.6432 \n",
      "2021-05-22 12:31:44 [INFO]\t[EVAL] Class IoU: \n",
      "[0.499 0.954]\n",
      "2021-05-22 12:31:44 [INFO]\t[EVAL] Class Acc: \n",
      "[0.8201 0.9637]\n",
      "2021-05-22 12:31:48 [INFO]\t[EVAL] The model with the best validation mIoU (0.7265) was saved at iter 640.\n",
      "2021-05-22 12:31:59 [INFO]\t[TRAIN] epoch=3, iter=650/3200, loss=0.9351, lr=0.000254, batch_cost=1.1236, reader_cost=0.07751, ips=1.7801 samples/sec | ETA 00:47:45\n",
      "2021-05-22 12:32:10 [INFO]\t[TRAIN] epoch=3, iter=660/3200, loss=0.9763, lr=0.000254, batch_cost=1.0415, reader_cost=0.00024, ips=1.9204 samples/sec | ETA 00:44:05\n",
      "2021-05-22 12:32:20 [INFO]\t[TRAIN] epoch=3, iter=670/3200, loss=0.9567, lr=0.000253, batch_cost=1.0419, reader_cost=0.00020, ips=1.9195 samples/sec | ETA 00:43:56\n",
      "2021-05-22 12:32:31 [INFO]\t[TRAIN] epoch=3, iter=680/3200, loss=0.9850, lr=0.000252, batch_cost=1.0415, reader_cost=0.00021, ips=1.9203 samples/sec | ETA 00:43:44\n",
      "2021-05-22 12:32:41 [INFO]\t[TRAIN] epoch=3, iter=690/3200, loss=0.9476, lr=0.000252, batch_cost=1.0424, reader_cost=0.00019, ips=1.9186 samples/sec | ETA 00:43:36\n",
      "2021-05-22 12:32:52 [INFO]\t[TRAIN] epoch=3, iter=700/3200, loss=0.8653, lr=0.000251, batch_cost=1.0467, reader_cost=0.00022, ips=1.9108 samples/sec | ETA 00:43:36\n",
      "2021-05-22 12:33:02 [INFO]\t[TRAIN] epoch=3, iter=710/3200, loss=0.8059, lr=0.000250, batch_cost=1.0428, reader_cost=0.00020, ips=1.9179 samples/sec | ETA 00:43:16\n",
      "2021-05-22 12:33:13 [INFO]\t[TRAIN] epoch=3, iter=720/3200, loss=0.8529, lr=0.000250, batch_cost=1.0443, reader_cost=0.00023, ips=1.9151 samples/sec | ETA 00:43:09\n",
      "2021-05-22 12:33:23 [INFO]\t[TRAIN] epoch=3, iter=730/3200, loss=0.9088, lr=0.000249, batch_cost=1.0431, reader_cost=0.00021, ips=1.9174 samples/sec | ETA 00:42:56\n",
      "2021-05-22 12:33:33 [INFO]\t[TRAIN] epoch=3, iter=740/3200, loss=0.8250, lr=0.000248, batch_cost=1.0432, reader_cost=0.00020, ips=1.9172 samples/sec | ETA 00:42:46\n",
      "2021-05-22 12:33:44 [INFO]\t[TRAIN] epoch=3, iter=750/3200, loss=0.9485, lr=0.000247, batch_cost=1.0472, reader_cost=0.00021, ips=1.9099 samples/sec | ETA 00:42:45\n",
      "2021-05-22 12:33:54 [INFO]\t[TRAIN] epoch=3, iter=760/3200, loss=0.8272, lr=0.000247, batch_cost=1.0437, reader_cost=0.00019, ips=1.9163 samples/sec | ETA 00:42:26\n",
      "2021-05-22 12:34:05 [INFO]\t[TRAIN] epoch=3, iter=770/3200, loss=0.8636, lr=0.000246, batch_cost=1.0452, reader_cost=0.00027, ips=1.9136 samples/sec | ETA 00:42:19\n",
      "2021-05-22 12:34:15 [INFO]\t[TRAIN] epoch=3, iter=780/3200, loss=0.7753, lr=0.000245, batch_cost=1.0436, reader_cost=0.00021, ips=1.9164 samples/sec | ETA 00:42:05\n",
      "2021-05-22 12:34:26 [INFO]\t[TRAIN] epoch=3, iter=790/3200, loss=0.8005, lr=0.000245, batch_cost=1.0433, reader_cost=0.00020, ips=1.9171 samples/sec | ETA 00:41:54\n",
      "2021-05-22 12:34:36 [INFO]\t[TRAIN] epoch=3, iter=800/3200, loss=0.8623, lr=0.000244, batch_cost=1.0433, reader_cost=0.00020, ips=1.9169 samples/sec | ETA 00:41:43\n",
      "2021-05-22 12:34:46 [INFO]\t[TRAIN] epoch=3, iter=810/3200, loss=1.1393, lr=0.000243, batch_cost=1.0436, reader_cost=0.00019, ips=1.9164 samples/sec | ETA 00:41:34\n",
      "2021-05-22 12:34:57 [INFO]\t[TRAIN] epoch=3, iter=820/3200, loss=1.0404, lr=0.000243, batch_cost=1.0442, reader_cost=0.00025, ips=1.9154 samples/sec | ETA 00:41:25\n",
      "2021-05-22 12:35:07 [INFO]\t[TRAIN] epoch=3, iter=830/3200, loss=0.9193, lr=0.000242, batch_cost=1.0435, reader_cost=0.00021, ips=1.9166 samples/sec | ETA 00:41:13\n",
      "2021-05-22 12:35:18 [INFO]\t[TRAIN] epoch=3, iter=840/3200, loss=0.9803, lr=0.000241, batch_cost=1.0443, reader_cost=0.00020, ips=1.9151 samples/sec | ETA 00:41:04\n",
      "2021-05-22 12:35:28 [INFO]\t[TRAIN] epoch=3, iter=850/3200, loss=0.8122, lr=0.000240, batch_cost=1.0454, reader_cost=0.00022, ips=1.9132 samples/sec | ETA 00:40:56\n",
      "2021-05-22 12:35:39 [INFO]\t[TRAIN] epoch=3, iter=860/3200, loss=1.0262, lr=0.000240, batch_cost=1.0447, reader_cost=0.00023, ips=1.9145 samples/sec | ETA 00:40:44\n",
      "2021-05-22 12:35:49 [INFO]\t[TRAIN] epoch=3, iter=870/3200, loss=1.0609, lr=0.000239, batch_cost=1.0432, reader_cost=0.00020, ips=1.9172 samples/sec | ETA 00:40:30\n",
      "2021-05-22 12:36:00 [INFO]\t[TRAIN] epoch=3, iter=880/3200, loss=0.7778, lr=0.000238, batch_cost=1.0439, reader_cost=0.00020, ips=1.9159 samples/sec | ETA 00:40:21\n",
      "2021-05-22 12:36:10 [INFO]\t[TRAIN] epoch=3, iter=890/3200, loss=0.9563, lr=0.000238, batch_cost=1.0434, reader_cost=0.00019, ips=1.9169 samples/sec | ETA 00:40:10\n",
      "2021-05-22 12:36:20 [INFO]\t[TRAIN] epoch=3, iter=900/3200, loss=0.9309, lr=0.000237, batch_cost=1.0457, reader_cost=0.00024, ips=1.9126 samples/sec | ETA 00:40:05\n",
      "2021-05-22 12:36:31 [INFO]\t[TRAIN] epoch=3, iter=910/3200, loss=0.7933, lr=0.000236, batch_cost=1.0436, reader_cost=0.00021, ips=1.9165 samples/sec | ETA 00:39:49\n",
      "2021-05-22 12:36:41 [INFO]\t[TRAIN] epoch=3, iter=920/3200, loss=0.8857, lr=0.000236, batch_cost=1.0449, reader_cost=0.00020, ips=1.9140 samples/sec | ETA 00:39:42\n",
      "2021-05-22 12:36:52 [INFO]\t[TRAIN] epoch=3, iter=930/3200, loss=0.8183, lr=0.000235, batch_cost=1.0449, reader_cost=0.00021, ips=1.9141 samples/sec | ETA 00:39:31\n",
      "2021-05-22 12:37:02 [INFO]\t[TRAIN] epoch=3, iter=940/3200, loss=0.8751, lr=0.000234, batch_cost=1.0452, reader_cost=0.00027, ips=1.9135 samples/sec | ETA 00:39:22\n",
      "2021-05-22 12:37:13 [INFO]\t[TRAIN] epoch=3, iter=950/3200, loss=0.8161, lr=0.000233, batch_cost=1.0447, reader_cost=0.00021, ips=1.9145 samples/sec | ETA 00:39:10\n",
      "2021-05-22 12:37:23 [INFO]\t[TRAIN] epoch=3, iter=960/3200, loss=0.8381, lr=0.000233, batch_cost=1.0461, reader_cost=0.00023, ips=1.9119 samples/sec | ETA 00:39:03\n",
      "2021-05-22 12:37:23 [INFO]\tStart evaluating (total_samples=160, total_iters=160)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 52s 327ms/step - batch_cost: 0.1635 - reader cost: 0.142\n",
      "160/160 [==============================] - 52s 328ms/step - batch_cost: 0.1630 - reader cost: 0.1422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-22 12:38:16 [INFO]\t[EVAL] #Images=160 mIoU=0.4941 Acc=0.9881 Kappa=0.0000 \n",
      "2021-05-22 12:38:16 [INFO]\t[EVAL] Class IoU: \n",
      "[0.     0.9881]\n",
      "2021-05-22 12:38:16 [INFO]\t[EVAL] Class Acc: \n",
      "[0.     0.9881]\n",
      "2021-05-22 12:38:16 [INFO]\t[EVAL] #Images=160 mIoU=0.6904 Acc=0.9531 Kappa=0.5788 \n",
      "2021-05-22 12:38:16 [INFO]\t[EVAL] Class IoU: \n",
      "[0.4294 0.9514]\n",
      "2021-05-22 12:38:16 [INFO]\t[EVAL] Class Acc: \n",
      "[0.8978 0.9554]\n",
      "2021-05-22 12:38:19 [INFO]\t[EVAL] The model with the best validation mIoU (0.7265) was saved at iter 640.\n",
      "2021-05-22 12:38:30 [INFO]\t[TRAIN] epoch=4, iter=970/3200, loss=0.8444, lr=0.000232, batch_cost=1.1018, reader_cost=0.05732, ips=1.8152 samples/sec | ETA 00:40:57\n",
      "2021-05-22 12:38:40 [INFO]\t[TRAIN] epoch=4, iter=980/3200, loss=0.8692, lr=0.000231, batch_cost=1.0404, reader_cost=0.00023, ips=1.9224 samples/sec | ETA 00:38:29\n",
      "2021-05-22 12:38:51 [INFO]\t[TRAIN] epoch=4, iter=990/3200, loss=0.8122, lr=0.000231, batch_cost=1.0412, reader_cost=0.00017, ips=1.9209 samples/sec | ETA 00:38:20\n",
      "2021-05-22 12:39:01 [INFO]\t[TRAIN] epoch=4, iter=1000/3200, loss=0.8745, lr=0.000230, batch_cost=1.0400, reader_cost=0.00018, ips=1.9230 samples/sec | ETA 00:38:08\n",
      "2021-05-22 12:39:12 [INFO]\t[TRAIN] epoch=4, iter=1010/3200, loss=0.7925, lr=0.000229, batch_cost=1.0405, reader_cost=0.00017, ips=1.9221 samples/sec | ETA 00:37:58\n",
      "2021-05-22 12:39:22 [INFO]\t[TRAIN] epoch=4, iter=1020/3200, loss=0.9481, lr=0.000229, batch_cost=1.0414, reader_cost=0.00018, ips=1.9204 samples/sec | ETA 00:37:50\n",
      "2021-05-22 12:39:32 [INFO]\t[TRAIN] epoch=4, iter=1030/3200, loss=0.9307, lr=0.000228, batch_cost=1.0419, reader_cost=0.00020, ips=1.9196 samples/sec | ETA 00:37:40\n",
      "2021-05-22 12:39:43 [INFO]\t[TRAIN] epoch=4, iter=1040/3200, loss=0.8585, lr=0.000227, batch_cost=1.0413, reader_cost=0.00017, ips=1.9208 samples/sec | ETA 00:37:29\n",
      "2021-05-22 12:39:53 [INFO]\t[TRAIN] epoch=4, iter=1050/3200, loss=0.8443, lr=0.000226, batch_cost=1.0417, reader_cost=0.00021, ips=1.9199 samples/sec | ETA 00:37:19\n",
      "2021-05-22 12:40:04 [INFO]\t[TRAIN] epoch=4, iter=1060/3200, loss=0.8172, lr=0.000226, batch_cost=1.0427, reader_cost=0.00019, ips=1.9180 samples/sec | ETA 00:37:11\n",
      "2021-05-22 12:40:14 [INFO]\t[TRAIN] epoch=4, iter=1070/3200, loss=0.8869, lr=0.000225, batch_cost=1.0420, reader_cost=0.00023, ips=1.9194 samples/sec | ETA 00:36:59\n",
      "2021-05-22 12:40:25 [INFO]\t[TRAIN] epoch=4, iter=1080/3200, loss=1.0032, lr=0.000224, batch_cost=1.0431, reader_cost=0.00021, ips=1.9174 samples/sec | ETA 00:36:51\n",
      "2021-05-22 12:40:35 [INFO]\t[TRAIN] epoch=4, iter=1090/3200, loss=1.1523, lr=0.000224, batch_cost=1.0426, reader_cost=0.00021, ips=1.9183 samples/sec | ETA 00:36:39\n",
      "2021-05-22 12:40:45 [INFO]\t[TRAIN] epoch=4, iter=1100/3200, loss=0.9181, lr=0.000223, batch_cost=1.0431, reader_cost=0.00019, ips=1.9173 samples/sec | ETA 00:36:30\n",
      "2021-05-22 12:40:56 [INFO]\t[TRAIN] epoch=4, iter=1110/3200, loss=0.8967, lr=0.000222, batch_cost=1.0431, reader_cost=0.00021, ips=1.9174 samples/sec | ETA 00:36:20\n",
      "2021-05-22 12:41:06 [INFO]\t[TRAIN] epoch=4, iter=1120/3200, loss=0.8306, lr=0.000222, batch_cost=1.0426, reader_cost=0.00021, ips=1.9182 samples/sec | ETA 00:36:08\n",
      "2021-05-22 12:41:17 [INFO]\t[TRAIN] epoch=4, iter=1130/3200, loss=0.7950, lr=0.000221, batch_cost=1.0427, reader_cost=0.00019, ips=1.9180 samples/sec | ETA 00:35:58\n",
      "2021-05-22 12:41:27 [INFO]\t[TRAIN] epoch=4, iter=1140/3200, loss=0.8514, lr=0.000220, batch_cost=1.0431, reader_cost=0.00022, ips=1.9173 samples/sec | ETA 00:35:48\n",
      "2021-05-22 12:41:38 [INFO]\t[TRAIN] epoch=4, iter=1150/3200, loss=1.0020, lr=0.000219, batch_cost=1.0436, reader_cost=0.00021, ips=1.9164 samples/sec | ETA 00:35:39\n",
      "2021-05-22 12:41:48 [INFO]\t[TRAIN] epoch=4, iter=1160/3200, loss=0.8472, lr=0.000219, batch_cost=1.0443, reader_cost=0.00017, ips=1.9151 samples/sec | ETA 00:35:30\n",
      "2021-05-22 12:41:58 [INFO]\t[TRAIN] epoch=4, iter=1170/3200, loss=0.9826, lr=0.000218, batch_cost=1.0429, reader_cost=0.00020, ips=1.9176 samples/sec | ETA 00:35:17\n",
      "2021-05-22 12:42:09 [INFO]\t[TRAIN] epoch=4, iter=1180/3200, loss=0.8400, lr=0.000217, batch_cost=1.0446, reader_cost=0.00019, ips=1.9146 samples/sec | ETA 00:35:10\n",
      "2021-05-22 12:42:19 [INFO]\t[TRAIN] epoch=4, iter=1190/3200, loss=0.9789, lr=0.000217, batch_cost=1.0441, reader_cost=0.00018, ips=1.9155 samples/sec | ETA 00:34:58\n",
      "2021-05-22 12:42:30 [INFO]\t[TRAIN] epoch=4, iter=1200/3200, loss=0.8184, lr=0.000216, batch_cost=1.0447, reader_cost=0.00021, ips=1.9144 samples/sec | ETA 00:34:49\n",
      "2021-05-22 12:42:40 [INFO]\t[TRAIN] epoch=4, iter=1210/3200, loss=0.8216, lr=0.000215, batch_cost=1.0435, reader_cost=0.00026, ips=1.9166 samples/sec | ETA 00:34:36\n",
      "2021-05-22 12:42:51 [INFO]\t[TRAIN] epoch=4, iter=1220/3200, loss=0.9213, lr=0.000215, batch_cost=1.0441, reader_cost=0.00022, ips=1.9155 samples/sec | ETA 00:34:27\n",
      "2021-05-22 12:43:01 [INFO]\t[TRAIN] epoch=4, iter=1230/3200, loss=1.0577, lr=0.000214, batch_cost=1.0444, reader_cost=0.00021, ips=1.9149 samples/sec | ETA 00:34:17\n",
      "2021-05-22 12:43:12 [INFO]\t[TRAIN] epoch=4, iter=1240/3200, loss=0.9272, lr=0.000213, batch_cost=1.0443, reader_cost=0.00027, ips=1.9151 samples/sec | ETA 00:34:06\n",
      "2021-05-22 12:43:22 [INFO]\t[TRAIN] epoch=4, iter=1250/3200, loss=0.8755, lr=0.000212, batch_cost=1.0453, reader_cost=0.00024, ips=1.9134 samples/sec | ETA 00:33:58\n",
      "2021-05-22 12:43:32 [INFO]\t[TRAIN] epoch=4, iter=1260/3200, loss=0.8295, lr=0.000212, batch_cost=1.0443, reader_cost=0.00021, ips=1.9152 samples/sec | ETA 00:33:45\n",
      "2021-05-22 12:43:43 [INFO]\t[TRAIN] epoch=4, iter=1270/3200, loss=0.9933, lr=0.000211, batch_cost=1.0437, reader_cost=0.00018, ips=1.9163 samples/sec | ETA 00:33:34\n",
      "2021-05-22 12:43:53 [INFO]\t[TRAIN] epoch=4, iter=1280/3200, loss=0.8299, lr=0.000210, batch_cost=1.0435, reader_cost=0.00018, ips=1.9166 samples/sec | ETA 00:33:23\n",
      "2021-05-22 12:43:53 [INFO]\tStart evaluating (total_samples=160, total_iters=160)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 53s 332ms/step - batch_cost: 0.1655 - reader cost: 0.144\n",
      "160/160 [==============================] - 53s 332ms/step - batch_cost: 0.1650 - reader cost: 0.1444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-22 12:44:47 [INFO]\t[EVAL] #Images=160 mIoU=0.4941 Acc=0.9881 Kappa=0.0000 \n",
      "2021-05-22 12:44:47 [INFO]\t[EVAL] Class IoU: \n",
      "[0.     0.9881]\n",
      "2021-05-22 12:44:47 [INFO]\t[EVAL] Class Acc: \n",
      "[0.     0.9881]\n",
      "2021-05-22 12:44:47 [INFO]\t[EVAL] #Images=160 mIoU=0.7166 Acc=0.9558 Kappa=0.6260 \n",
      "2021-05-22 12:44:47 [INFO]\t[EVAL] Class IoU: \n",
      "[0.4794 0.9539]\n",
      "2021-05-22 12:44:47 [INFO]\t[EVAL] Class Acc: \n",
      "[0.8563 0.9607]\n",
      "2021-05-22 12:44:50 [INFO]\t[EVAL] The model with the best validation mIoU (0.7265) was saved at iter 640.\n",
      "2021-05-22 12:45:01 [INFO]\t[TRAIN] epoch=5, iter=1290/3200, loss=1.0175, lr=0.000210, batch_cost=1.0957, reader_cost=0.04828, ips=1.8253 samples/sec | ETA 00:34:52\n",
      "2021-05-22 12:45:11 [INFO]\t[TRAIN] epoch=5, iter=1300/3200, loss=1.1640, lr=0.000209, batch_cost=1.0421, reader_cost=0.00020, ips=1.9192 samples/sec | ETA 00:33:00\n",
      "2021-05-22 12:45:22 [INFO]\t[TRAIN] epoch=5, iter=1310/3200, loss=1.0037, lr=0.000208, batch_cost=1.0419, reader_cost=0.00021, ips=1.9195 samples/sec | ETA 00:32:49\n",
      "2021-05-22 12:45:32 [INFO]\t[TRAIN] epoch=5, iter=1320/3200, loss=0.7879, lr=0.000207, batch_cost=1.0424, reader_cost=0.00023, ips=1.9187 samples/sec | ETA 00:32:39\n",
      "2021-05-22 12:45:42 [INFO]\t[TRAIN] epoch=5, iter=1330/3200, loss=0.8230, lr=0.000207, batch_cost=1.0434, reader_cost=0.00021, ips=1.9168 samples/sec | ETA 00:32:31\n",
      "2021-05-22 12:45:53 [INFO]\t[TRAIN] epoch=5, iter=1340/3200, loss=0.8607, lr=0.000206, batch_cost=1.0439, reader_cost=0.00022, ips=1.9160 samples/sec | ETA 00:32:21\n",
      "2021-05-22 12:46:03 [INFO]\t[TRAIN] epoch=5, iter=1350/3200, loss=0.7992, lr=0.000205, batch_cost=1.0427, reader_cost=0.00018, ips=1.9181 samples/sec | ETA 00:32:09\n",
      "2021-05-22 12:46:14 [INFO]\t[TRAIN] epoch=5, iter=1360/3200, loss=0.8276, lr=0.000205, batch_cost=1.0442, reader_cost=0.00021, ips=1.9154 samples/sec | ETA 00:32:01\n",
      "2021-05-22 12:46:24 [INFO]\t[TRAIN] epoch=5, iter=1370/3200, loss=0.8661, lr=0.000204, batch_cost=1.0443, reader_cost=0.00018, ips=1.9151 samples/sec | ETA 00:31:51\n",
      "2021-05-22 12:46:35 [INFO]\t[TRAIN] epoch=5, iter=1380/3200, loss=0.8550, lr=0.000203, batch_cost=1.0482, reader_cost=0.00019, ips=1.9081 samples/sec | ETA 00:31:47\n",
      "2021-05-22 12:46:45 [INFO]\t[TRAIN] epoch=5, iter=1390/3200, loss=0.8137, lr=0.000203, batch_cost=1.0444, reader_cost=0.00026, ips=1.9149 samples/sec | ETA 00:31:30\n",
      "2021-05-22 12:46:56 [INFO]\t[TRAIN] epoch=5, iter=1400/3200, loss=0.7780, lr=0.000202, batch_cost=1.0450, reader_cost=0.00021, ips=1.9138 samples/sec | ETA 00:31:21\n",
      "2021-05-22 12:47:06 [INFO]\t[TRAIN] epoch=5, iter=1410/3200, loss=0.9772, lr=0.000201, batch_cost=1.0447, reader_cost=0.00020, ips=1.9145 samples/sec | ETA 00:31:09\n",
      "2021-05-22 12:47:16 [INFO]\t[TRAIN] epoch=5, iter=1420/3200, loss=0.8893, lr=0.000200, batch_cost=1.0459, reader_cost=0.00021, ips=1.9122 samples/sec | ETA 00:31:01\n",
      "2021-05-22 12:47:27 [INFO]\t[TRAIN] epoch=5, iter=1430/3200, loss=0.8359, lr=0.000200, batch_cost=1.0449, reader_cost=0.00017, ips=1.9141 samples/sec | ETA 00:30:49\n",
      "2021-05-22 12:47:37 [INFO]\t[TRAIN] epoch=5, iter=1440/3200, loss=0.7909, lr=0.000199, batch_cost=1.0445, reader_cost=0.00018, ips=1.9149 samples/sec | ETA 00:30:38\n",
      "2021-05-22 12:47:48 [INFO]\t[TRAIN] epoch=5, iter=1450/3200, loss=0.8935, lr=0.000198, batch_cost=1.0450, reader_cost=0.00025, ips=1.9139 samples/sec | ETA 00:30:28\n",
      "2021-05-22 12:47:58 [INFO]\t[TRAIN] epoch=5, iter=1460/3200, loss=0.7730, lr=0.000198, batch_cost=1.0445, reader_cost=0.00018, ips=1.9148 samples/sec | ETA 00:30:17\n",
      "2021-05-22 12:48:09 [INFO]\t[TRAIN] epoch=5, iter=1470/3200, loss=0.9540, lr=0.000197, batch_cost=1.0446, reader_cost=0.00016, ips=1.9146 samples/sec | ETA 00:30:07\n",
      "2021-05-22 12:48:19 [INFO]\t[TRAIN] epoch=5, iter=1480/3200, loss=0.8358, lr=0.000196, batch_cost=1.0519, reader_cost=0.00021, ips=1.9013 samples/sec | ETA 00:30:09\n",
      "2021-05-22 12:48:30 [INFO]\t[TRAIN] epoch=5, iter=1490/3200, loss=0.9684, lr=0.000196, batch_cost=1.0451, reader_cost=0.00023, ips=1.9137 samples/sec | ETA 00:29:47\n",
      "2021-05-22 12:48:40 [INFO]\t[TRAIN] epoch=5, iter=1500/3200, loss=0.8667, lr=0.000195, batch_cost=1.0441, reader_cost=0.00021, ips=1.9154 samples/sec | ETA 00:29:35\n",
      "2021-05-22 12:48:51 [INFO]\t[TRAIN] epoch=5, iter=1510/3200, loss=0.9929, lr=0.000194, batch_cost=1.0439, reader_cost=0.00019, ips=1.9160 samples/sec | ETA 00:29:24\n",
      "2021-05-22 12:49:01 [INFO]\t[TRAIN] epoch=5, iter=1520/3200, loss=0.9258, lr=0.000193, batch_cost=1.0448, reader_cost=0.00023, ips=1.9143 samples/sec | ETA 00:29:15\n",
      "2021-05-22 12:49:11 [INFO]\t[TRAIN] epoch=5, iter=1530/3200, loss=0.9655, lr=0.000193, batch_cost=1.0442, reader_cost=0.00019, ips=1.9153 samples/sec | ETA 00:29:03\n",
      "2021-05-22 12:49:22 [INFO]\t[TRAIN] epoch=5, iter=1540/3200, loss=1.0354, lr=0.000192, batch_cost=1.0446, reader_cost=0.00019, ips=1.9146 samples/sec | ETA 00:28:54\n",
      "2021-05-22 12:49:32 [INFO]\t[TRAIN] epoch=5, iter=1550/3200, loss=0.7835, lr=0.000191, batch_cost=1.0446, reader_cost=0.00019, ips=1.9145 samples/sec | ETA 00:28:43\n",
      "2021-05-22 12:49:43 [INFO]\t[TRAIN] epoch=5, iter=1560/3200, loss=0.7496, lr=0.000191, batch_cost=1.0437, reader_cost=0.00022, ips=1.9163 samples/sec | ETA 00:28:31\n",
      "2021-05-22 12:49:53 [INFO]\t[TRAIN] epoch=5, iter=1570/3200, loss=0.9695, lr=0.000190, batch_cost=1.0433, reader_cost=0.00020, ips=1.9171 samples/sec | ETA 00:28:20\n",
      "2021-05-22 12:50:04 [INFO]\t[TRAIN] epoch=5, iter=1580/3200, loss=0.7502, lr=0.000189, batch_cost=1.0438, reader_cost=0.00018, ips=1.9161 samples/sec | ETA 00:28:10\n",
      "2021-05-22 12:50:14 [INFO]\t[TRAIN] epoch=5, iter=1590/3200, loss=0.9374, lr=0.000189, batch_cost=1.0439, reader_cost=0.00018, ips=1.9159 samples/sec | ETA 00:28:00\n",
      "2021-05-22 12:50:25 [INFO]\t[TRAIN] epoch=5, iter=1600/3200, loss=0.7803, lr=0.000188, batch_cost=1.0456, reader_cost=0.00019, ips=1.9128 samples/sec | ETA 00:27:52\n",
      "2021-05-22 12:50:25 [INFO]\tStart evaluating (total_samples=160, total_iters=160)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 52s 322ms/step - batch_cost: 0.1608 - reader cost: 0.140\n",
      "160/160 [==============================] - 52s 322ms/step - batch_cost: 0.1603 - reader cost: 0.1401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-22 12:51:16 [INFO]\t[EVAL] #Images=160 mIoU=0.4941 Acc=0.9881 Kappa=0.0000 \n",
      "2021-05-22 12:51:16 [INFO]\t[EVAL] Class IoU: \n",
      "[0.     0.9881]\n",
      "2021-05-22 12:51:16 [INFO]\t[EVAL] Class Acc: \n",
      "[0.     0.9881]\n",
      "2021-05-22 12:51:16 [INFO]\t[EVAL] #Images=160 mIoU=0.7058 Acc=0.9541 Kappa=0.6068 \n",
      "2021-05-22 12:51:16 [INFO]\t[EVAL] Class IoU: \n",
      "[0.4593 0.9522]\n",
      "2021-05-22 12:51:16 [INFO]\t[EVAL] Class Acc: \n",
      "[0.8522 0.959 ]\n",
      "2021-05-22 12:51:19 [INFO]\t[EVAL] The model with the best validation mIoU (0.7265) was saved at iter 640.\n",
      "2021-05-22 12:51:30 [INFO]\t[TRAIN] epoch=6, iter=1610/3200, loss=0.8056, lr=0.000187, batch_cost=1.1094, reader_cost=0.06452, ips=1.8027 samples/sec | ETA 00:29:24\n",
      "2021-05-22 12:51:41 [INFO]\t[TRAIN] epoch=6, iter=1620/3200, loss=0.9162, lr=0.000186, batch_cost=1.0410, reader_cost=0.00017, ips=1.9213 samples/sec | ETA 00:27:24\n",
      "2021-05-22 12:51:51 [INFO]\t[TRAIN] epoch=6, iter=1630/3200, loss=0.9273, lr=0.000186, batch_cost=1.0426, reader_cost=0.00019, ips=1.9182 samples/sec | ETA 00:27:16\n",
      "2021-05-22 12:52:02 [INFO]\t[TRAIN] epoch=6, iter=1640/3200, loss=1.0804, lr=0.000185, batch_cost=1.0436, reader_cost=0.00022, ips=1.9164 samples/sec | ETA 00:27:08\n",
      "2021-05-22 12:52:12 [INFO]\t[TRAIN] epoch=6, iter=1650/3200, loss=0.8835, lr=0.000184, batch_cost=1.0430, reader_cost=0.00018, ips=1.9176 samples/sec | ETA 00:26:56\n",
      "2021-05-22 12:52:22 [INFO]\t[TRAIN] epoch=6, iter=1660/3200, loss=0.8392, lr=0.000184, batch_cost=1.0428, reader_cost=0.00019, ips=1.9178 samples/sec | ETA 00:26:45\n",
      "2021-05-22 12:52:33 [INFO]\t[TRAIN] epoch=6, iter=1670/3200, loss=1.1679, lr=0.000183, batch_cost=1.0432, reader_cost=0.00020, ips=1.9173 samples/sec | ETA 00:26:36\n",
      "2021-05-22 12:52:43 [INFO]\t[TRAIN] epoch=6, iter=1680/3200, loss=0.8861, lr=0.000182, batch_cost=1.0422, reader_cost=0.00021, ips=1.9189 samples/sec | ETA 00:26:24\n",
      "2021-05-22 12:52:54 [INFO]\t[TRAIN] epoch=6, iter=1690/3200, loss=0.8053, lr=0.000182, batch_cost=1.0440, reader_cost=0.00020, ips=1.9157 samples/sec | ETA 00:26:16\n",
      "2021-05-22 12:53:04 [INFO]\t[TRAIN] epoch=6, iter=1700/3200, loss=0.8122, lr=0.000181, batch_cost=1.0432, reader_cost=0.00019, ips=1.9172 samples/sec | ETA 00:26:04\n",
      "2021-05-22 12:53:15 [INFO]\t[TRAIN] epoch=6, iter=1710/3200, loss=0.9779, lr=0.000180, batch_cost=1.0436, reader_cost=0.00018, ips=1.9164 samples/sec | ETA 00:25:55\n",
      "2021-05-22 12:53:25 [INFO]\t[TRAIN] epoch=6, iter=1720/3200, loss=0.8772, lr=0.000179, batch_cost=1.0436, reader_cost=0.00017, ips=1.9164 samples/sec | ETA 00:25:44\n",
      "2021-05-22 12:53:36 [INFO]\t[TRAIN] epoch=6, iter=1730/3200, loss=0.7908, lr=0.000179, batch_cost=1.0442, reader_cost=0.00019, ips=1.9153 samples/sec | ETA 00:25:35\n",
      "2021-05-22 12:53:46 [INFO]\t[TRAIN] epoch=6, iter=1740/3200, loss=0.7829, lr=0.000178, batch_cost=1.0445, reader_cost=0.00022, ips=1.9149 samples/sec | ETA 00:25:24\n",
      "2021-05-22 12:53:57 [INFO]\t[TRAIN] epoch=6, iter=1750/3200, loss=0.8624, lr=0.000177, batch_cost=1.0516, reader_cost=0.00039, ips=1.9018 samples/sec | ETA 00:25:24\n",
      "2021-05-22 12:54:07 [INFO]\t[TRAIN] epoch=6, iter=1760/3200, loss=0.8083, lr=0.000177, batch_cost=1.0448, reader_cost=0.00017, ips=1.9143 samples/sec | ETA 00:25:04\n",
      "2021-05-22 12:54:17 [INFO]\t[TRAIN] epoch=6, iter=1770/3200, loss=0.8006, lr=0.000176, batch_cost=1.0440, reader_cost=0.00018, ips=1.9157 samples/sec | ETA 00:24:52\n",
      "2021-05-22 12:54:28 [INFO]\t[TRAIN] epoch=6, iter=1780/3200, loss=0.7957, lr=0.000175, batch_cost=1.0442, reader_cost=0.00026, ips=1.9153 samples/sec | ETA 00:24:42\n",
      "2021-05-22 12:54:38 [INFO]\t[TRAIN] epoch=6, iter=1790/3200, loss=0.9430, lr=0.000175, batch_cost=1.0442, reader_cost=0.00025, ips=1.9154 samples/sec | ETA 00:24:32\n",
      "2021-05-22 12:54:49 [INFO]\t[TRAIN] epoch=6, iter=1800/3200, loss=0.8465, lr=0.000174, batch_cost=1.0454, reader_cost=0.00022, ips=1.9131 samples/sec | ETA 00:24:23\n",
      "2021-05-22 12:54:59 [INFO]\t[TRAIN] epoch=6, iter=1810/3200, loss=0.8709, lr=0.000173, batch_cost=1.0454, reader_cost=0.00023, ips=1.9132 samples/sec | ETA 00:24:13\n",
      "2021-05-22 12:55:10 [INFO]\t[TRAIN] epoch=6, iter=1820/3200, loss=0.9308, lr=0.000172, batch_cost=1.0460, reader_cost=0.00022, ips=1.9121 samples/sec | ETA 00:24:03\n",
      "2021-05-22 12:55:20 [INFO]\t[TRAIN] epoch=6, iter=1830/3200, loss=0.8534, lr=0.000172, batch_cost=1.0433, reader_cost=0.00023, ips=1.9171 samples/sec | ETA 00:23:49\n",
      "2021-05-22 12:55:31 [INFO]\t[TRAIN] epoch=6, iter=1840/3200, loss=0.7588, lr=0.000171, batch_cost=1.0435, reader_cost=0.00025, ips=1.9167 samples/sec | ETA 00:23:39\n",
      "2021-05-22 12:55:41 [INFO]\t[TRAIN] epoch=6, iter=1850/3200, loss=0.8563, lr=0.000170, batch_cost=1.0439, reader_cost=0.00020, ips=1.9158 samples/sec | ETA 00:23:29\n",
      "2021-05-22 12:55:51 [INFO]\t[TRAIN] epoch=6, iter=1860/3200, loss=0.7668, lr=0.000170, batch_cost=1.0428, reader_cost=0.00019, ips=1.9179 samples/sec | ETA 00:23:17\n",
      "2021-05-22 12:56:02 [INFO]\t[TRAIN] epoch=6, iter=1870/3200, loss=0.8251, lr=0.000169, batch_cost=1.0435, reader_cost=0.00020, ips=1.9166 samples/sec | ETA 00:23:07\n",
      "2021-05-22 12:56:12 [INFO]\t[TRAIN] epoch=6, iter=1880/3200, loss=0.7858, lr=0.000168, batch_cost=1.0435, reader_cost=0.00017, ips=1.9165 samples/sec | ETA 00:22:57\n",
      "2021-05-22 12:56:23 [INFO]\t[TRAIN] epoch=6, iter=1890/3200, loss=0.9962, lr=0.000168, batch_cost=1.0429, reader_cost=0.00023, ips=1.9177 samples/sec | ETA 00:22:46\n",
      "2021-05-22 12:56:33 [INFO]\t[TRAIN] epoch=6, iter=1900/3200, loss=0.7937, lr=0.000167, batch_cost=1.0464, reader_cost=0.00018, ips=1.9113 samples/sec | ETA 00:22:40\n",
      "2021-05-22 12:56:44 [INFO]\t[TRAIN] epoch=6, iter=1910/3200, loss=0.8215, lr=0.000166, batch_cost=1.0427, reader_cost=0.00023, ips=1.9181 samples/sec | ETA 00:22:25\n",
      "2021-05-22 12:56:54 [INFO]\t[TRAIN] epoch=6, iter=1920/3200, loss=1.0556, lr=0.000165, batch_cost=1.0449, reader_cost=0.00022, ips=1.9140 samples/sec | ETA 00:22:17\n",
      "2021-05-22 12:56:54 [INFO]\tStart evaluating (total_samples=160, total_iters=160)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 52s 322ms/step - batch_cost: 0.1608 - reader cost: 0.140\n",
      "160/160 [==============================] - 52s 322ms/step - batch_cost: 0.1603 - reader cost: 0.1404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-22 12:57:46 [INFO]\t[EVAL] #Images=160 mIoU=0.4941 Acc=0.9881 Kappa=0.0000 \n",
      "2021-05-22 12:57:46 [INFO]\t[EVAL] Class IoU: \n",
      "[0.     0.9881]\n",
      "2021-05-22 12:57:46 [INFO]\t[EVAL] Class Acc: \n",
      "[0.     0.9881]\n",
      "2021-05-22 12:57:46 [INFO]\t[EVAL] #Images=160 mIoU=0.7466 Acc=0.9579 Kappa=0.6769 \n",
      "2021-05-22 12:57:46 [INFO]\t[EVAL] Class IoU: \n",
      "[0.5375 0.9557]\n",
      "2021-05-22 12:57:46 [INFO]\t[EVAL] Class Acc: \n",
      "[0.7901 0.9689]\n",
      "2021-05-22 12:57:50 [INFO]\t[EVAL] The model with the best validation mIoU (0.7466) was saved at iter 1920.\n",
      "2021-05-22 12:58:01 [INFO]\t[TRAIN] epoch=7, iter=1930/3200, loss=0.7443, lr=0.000165, batch_cost=1.1089, reader_cost=0.06379, ips=1.8035 samples/sec | ETA 00:23:28\n",
      "2021-05-22 12:58:12 [INFO]\t[TRAIN] epoch=7, iter=1940/3200, loss=0.7952, lr=0.000164, batch_cost=1.0411, reader_cost=0.00025, ips=1.9210 samples/sec | ETA 00:21:51\n",
      "2021-05-22 12:58:22 [INFO]\t[TRAIN] epoch=7, iter=1950/3200, loss=1.1699, lr=0.000163, batch_cost=1.0527, reader_cost=0.00020, ips=1.8998 samples/sec | ETA 00:21:55\n",
      "2021-05-22 12:58:33 [INFO]\t[TRAIN] epoch=7, iter=1960/3200, loss=0.8583, lr=0.000163, batch_cost=1.0427, reader_cost=0.00020, ips=1.9181 samples/sec | ETA 00:21:32\n",
      "2021-05-22 12:58:43 [INFO]\t[TRAIN] epoch=7, iter=1970/3200, loss=0.8744, lr=0.000162, batch_cost=1.0424, reader_cost=0.00018, ips=1.9187 samples/sec | ETA 00:21:22\n",
      "2021-05-22 12:58:53 [INFO]\t[TRAIN] epoch=7, iter=1980/3200, loss=0.9645, lr=0.000161, batch_cost=1.0422, reader_cost=0.00018, ips=1.9190 samples/sec | ETA 00:21:11\n",
      "2021-05-22 12:59:04 [INFO]\t[TRAIN] epoch=7, iter=1990/3200, loss=0.9147, lr=0.000161, batch_cost=1.0433, reader_cost=0.00020, ips=1.9170 samples/sec | ETA 00:21:02\n",
      "2021-05-22 12:59:14 [INFO]\t[TRAIN] epoch=7, iter=2000/3200, loss=0.8636, lr=0.000160, batch_cost=1.0433, reader_cost=0.00017, ips=1.9170 samples/sec | ETA 00:20:51\n",
      "2021-05-22 12:59:25 [INFO]\t[TRAIN] epoch=7, iter=2010/3200, loss=0.9170, lr=0.000159, batch_cost=1.0434, reader_cost=0.00017, ips=1.9168 samples/sec | ETA 00:20:41\n",
      "2021-05-22 12:59:35 [INFO]\t[TRAIN] epoch=7, iter=2020/3200, loss=0.7843, lr=0.000158, batch_cost=1.0439, reader_cost=0.00017, ips=1.9158 samples/sec | ETA 00:20:31\n",
      "2021-05-22 12:59:46 [INFO]\t[TRAIN] epoch=7, iter=2030/3200, loss=1.1520, lr=0.000158, batch_cost=1.0432, reader_cost=0.00017, ips=1.9172 samples/sec | ETA 00:20:20\n",
      "2021-05-22 12:59:56 [INFO]\t[TRAIN] epoch=7, iter=2040/3200, loss=0.8120, lr=0.000157, batch_cost=1.0436, reader_cost=0.00022, ips=1.9165 samples/sec | ETA 00:20:10\n",
      "2021-05-22 13:00:06 [INFO]\t[TRAIN] epoch=7, iter=2050/3200, loss=0.8268, lr=0.000156, batch_cost=1.0439, reader_cost=0.00018, ips=1.9158 samples/sec | ETA 00:20:00\n",
      "2021-05-22 13:00:17 [INFO]\t[TRAIN] epoch=7, iter=2060/3200, loss=0.9170, lr=0.000156, batch_cost=1.0471, reader_cost=0.00020, ips=1.9099 samples/sec | ETA 00:19:53\n",
      "2021-05-22 13:00:27 [INFO]\t[TRAIN] epoch=7, iter=2070/3200, loss=0.7825, lr=0.000155, batch_cost=1.0439, reader_cost=0.00019, ips=1.9158 samples/sec | ETA 00:19:39\n",
      "2021-05-22 13:00:38 [INFO]\t[TRAIN] epoch=7, iter=2080/3200, loss=0.8487, lr=0.000154, batch_cost=1.0436, reader_cost=0.00020, ips=1.9165 samples/sec | ETA 00:19:28\n",
      "2021-05-22 13:00:48 [INFO]\t[TRAIN] epoch=7, iter=2090/3200, loss=0.7952, lr=0.000153, batch_cost=1.0447, reader_cost=0.00018, ips=1.9144 samples/sec | ETA 00:19:19\n",
      "2021-05-22 13:00:59 [INFO]\t[TRAIN] epoch=7, iter=2100/3200, loss=0.7964, lr=0.000153, batch_cost=1.0446, reader_cost=0.00018, ips=1.9145 samples/sec | ETA 00:19:09\n",
      "2021-05-22 13:01:09 [INFO]\t[TRAIN] epoch=7, iter=2110/3200, loss=1.0499, lr=0.000152, batch_cost=1.0453, reader_cost=0.00017, ips=1.9133 samples/sec | ETA 00:18:59\n",
      "2021-05-22 13:01:20 [INFO]\t[TRAIN] epoch=7, iter=2120/3200, loss=0.8109, lr=0.000151, batch_cost=1.0453, reader_cost=0.00021, ips=1.9132 samples/sec | ETA 00:18:48\n",
      "2021-05-22 13:01:30 [INFO]\t[TRAIN] epoch=7, iter=2130/3200, loss=0.7619, lr=0.000151, batch_cost=1.0455, reader_cost=0.00019, ips=1.9129 samples/sec | ETA 00:18:38\n",
      "2021-05-22 13:01:41 [INFO]\t[TRAIN] epoch=7, iter=2140/3200, loss=0.7820, lr=0.000150, batch_cost=1.0443, reader_cost=0.00018, ips=1.9151 samples/sec | ETA 00:18:26\n",
      "2021-05-22 13:01:51 [INFO]\t[TRAIN] epoch=7, iter=2150/3200, loss=0.7642, lr=0.000149, batch_cost=1.0452, reader_cost=0.00020, ips=1.9136 samples/sec | ETA 00:18:17\n",
      "2021-05-22 13:02:01 [INFO]\t[TRAIN] epoch=7, iter=2160/3200, loss=0.7706, lr=0.000149, batch_cost=1.0436, reader_cost=0.00020, ips=1.9165 samples/sec | ETA 00:18:05\n",
      "2021-05-22 13:02:12 [INFO]\t[TRAIN] epoch=7, iter=2170/3200, loss=0.7209, lr=0.000148, batch_cost=1.0433, reader_cost=0.00018, ips=1.9170 samples/sec | ETA 00:17:54\n",
      "2021-05-22 13:02:22 [INFO]\t[TRAIN] epoch=7, iter=2180/3200, loss=1.0089, lr=0.000147, batch_cost=1.0434, reader_cost=0.00017, ips=1.9169 samples/sec | ETA 00:17:44\n",
      "2021-05-22 13:02:33 [INFO]\t[TRAIN] epoch=7, iter=2190/3200, loss=0.7926, lr=0.000146, batch_cost=1.0431, reader_cost=0.00018, ips=1.9174 samples/sec | ETA 00:17:33\n",
      "2021-05-22 13:02:43 [INFO]\t[TRAIN] epoch=7, iter=2200/3200, loss=0.8552, lr=0.000146, batch_cost=1.0432, reader_cost=0.00019, ips=1.9172 samples/sec | ETA 00:17:23\n",
      "2021-05-22 13:02:54 [INFO]\t[TRAIN] epoch=7, iter=2210/3200, loss=0.8416, lr=0.000145, batch_cost=1.0435, reader_cost=0.00017, ips=1.9166 samples/sec | ETA 00:17:13\n",
      "2021-05-22 13:03:04 [INFO]\t[TRAIN] epoch=7, iter=2220/3200, loss=0.8009, lr=0.000144, batch_cost=1.0428, reader_cost=0.00018, ips=1.9180 samples/sec | ETA 00:17:01\n",
      "2021-05-22 13:03:14 [INFO]\t[TRAIN] epoch=7, iter=2230/3200, loss=0.8403, lr=0.000144, batch_cost=1.0440, reader_cost=0.00019, ips=1.9157 samples/sec | ETA 00:16:52\n",
      "2021-05-22 13:03:25 [INFO]\t[TRAIN] epoch=7, iter=2240/3200, loss=1.0617, lr=0.000143, batch_cost=1.0443, reader_cost=0.00019, ips=1.9151 samples/sec | ETA 00:16:42\n",
      "2021-05-22 13:03:25 [INFO]\tStart evaluating (total_samples=160, total_iters=160)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 52s 322ms/step - batch_cost: 0.1608 - reader cost: 0.140\n",
      "160/160 [==============================] - 52s 322ms/step - batch_cost: 0.1603 - reader cost: 0.1401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-22 13:04:17 [INFO]\t[EVAL] #Images=160 mIoU=0.4941 Acc=0.9881 Kappa=0.0000 \n",
      "2021-05-22 13:04:17 [INFO]\t[EVAL] Class IoU: \n",
      "[0.     0.9881]\n",
      "2021-05-22 13:04:17 [INFO]\t[EVAL] Class Acc: \n",
      "[0.     0.9881]\n",
      "2021-05-22 13:04:17 [INFO]\t[EVAL] #Images=160 mIoU=0.7073 Acc=0.9546 Kappa=0.6095 \n",
      "2021-05-22 13:04:17 [INFO]\t[EVAL] Class IoU: \n",
      "[0.4619 0.9528]\n",
      "2021-05-22 13:04:17 [INFO]\t[EVAL] Class Acc: \n",
      "[0.8618 0.959 ]\n",
      "2021-05-22 13:04:20 [INFO]\t[EVAL] The model with the best validation mIoU (0.7466) was saved at iter 1920.\n",
      "2021-05-22 13:04:31 [INFO]\t[TRAIN] epoch=8, iter=2250/3200, loss=1.0006, lr=0.000142, batch_cost=1.1000, reader_cost=0.05490, ips=1.8182 samples/sec | ETA 00:17:24\n",
      "2021-05-22 13:04:41 [INFO]\t[TRAIN] epoch=8, iter=2260/3200, loss=0.9213, lr=0.000142, batch_cost=1.0419, reader_cost=0.00018, ips=1.9195 samples/sec | ETA 00:16:19\n",
      "2021-05-22 13:04:52 [INFO]\t[TRAIN] epoch=8, iter=2270/3200, loss=0.7834, lr=0.000141, batch_cost=1.0418, reader_cost=0.00023, ips=1.9198 samples/sec | ETA 00:16:08\n",
      "2021-05-22 13:05:02 [INFO]\t[TRAIN] epoch=8, iter=2280/3200, loss=0.7759, lr=0.000140, batch_cost=1.0432, reader_cost=0.00019, ips=1.9171 samples/sec | ETA 00:15:59\n",
      "2021-05-22 13:05:12 [INFO]\t[TRAIN] epoch=8, iter=2290/3200, loss=0.8533, lr=0.000139, batch_cost=1.0425, reader_cost=0.00018, ips=1.9185 samples/sec | ETA 00:15:48\n",
      "2021-05-22 13:05:23 [INFO]\t[TRAIN] epoch=8, iter=2300/3200, loss=0.7499, lr=0.000139, batch_cost=1.0426, reader_cost=0.00017, ips=1.9183 samples/sec | ETA 00:15:38\n",
      "2021-05-22 13:05:33 [INFO]\t[TRAIN] epoch=8, iter=2310/3200, loss=0.7418, lr=0.000138, batch_cost=1.0429, reader_cost=0.00020, ips=1.9178 samples/sec | ETA 00:15:28\n",
      "2021-05-22 13:05:44 [INFO]\t[TRAIN] epoch=8, iter=2320/3200, loss=0.9568, lr=0.000137, batch_cost=1.0489, reader_cost=0.00025, ips=1.9068 samples/sec | ETA 00:15:23\n",
      "2021-05-22 13:05:54 [INFO]\t[TRAIN] epoch=8, iter=2330/3200, loss=1.0262, lr=0.000137, batch_cost=1.0430, reader_cost=0.00017, ips=1.9176 samples/sec | ETA 00:15:07\n",
      "2021-05-22 13:06:05 [INFO]\t[TRAIN] epoch=8, iter=2340/3200, loss=1.0362, lr=0.000136, batch_cost=1.0418, reader_cost=0.00021, ips=1.9198 samples/sec | ETA 00:14:55\n",
      "2021-05-22 13:06:15 [INFO]\t[TRAIN] epoch=8, iter=2350/3200, loss=0.9393, lr=0.000135, batch_cost=1.0420, reader_cost=0.00017, ips=1.9194 samples/sec | ETA 00:14:45\n",
      "2021-05-22 13:06:26 [INFO]\t[TRAIN] epoch=8, iter=2360/3200, loss=0.8102, lr=0.000135, batch_cost=1.0428, reader_cost=0.00016, ips=1.9179 samples/sec | ETA 00:14:35\n",
      "2021-05-22 13:06:36 [INFO]\t[TRAIN] epoch=8, iter=2370/3200, loss=0.9303, lr=0.000134, batch_cost=1.0430, reader_cost=0.00017, ips=1.9175 samples/sec | ETA 00:14:25\n",
      "2021-05-22 13:06:46 [INFO]\t[TRAIN] epoch=8, iter=2380/3200, loss=0.9092, lr=0.000133, batch_cost=1.0438, reader_cost=0.00017, ips=1.9161 samples/sec | ETA 00:14:15\n",
      "2021-05-22 13:06:57 [INFO]\t[TRAIN] epoch=8, iter=2390/3200, loss=0.9958, lr=0.000132, batch_cost=1.0434, reader_cost=0.00017, ips=1.9168 samples/sec | ETA 00:14:05\n",
      "2021-05-22 13:07:07 [INFO]\t[TRAIN] epoch=8, iter=2400/3200, loss=0.8165, lr=0.000132, batch_cost=1.0434, reader_cost=0.00016, ips=1.9168 samples/sec | ETA 00:13:54\n",
      "2021-05-22 13:07:18 [INFO]\t[TRAIN] epoch=8, iter=2410/3200, loss=0.8895, lr=0.000131, batch_cost=1.0428, reader_cost=0.00016, ips=1.9178 samples/sec | ETA 00:13:43\n",
      "2021-05-22 13:07:28 [INFO]\t[TRAIN] epoch=8, iter=2420/3200, loss=0.7475, lr=0.000130, batch_cost=1.0439, reader_cost=0.00017, ips=1.9158 samples/sec | ETA 00:13:34\n",
      "2021-05-22 13:07:39 [INFO]\t[TRAIN] epoch=8, iter=2430/3200, loss=0.7274, lr=0.000130, batch_cost=1.0584, reader_cost=0.00019, ips=1.8897 samples/sec | ETA 00:13:34\n",
      "2021-05-22 13:07:49 [INFO]\t[TRAIN] epoch=8, iter=2440/3200, loss=0.8833, lr=0.000129, batch_cost=1.0438, reader_cost=0.00023, ips=1.9161 samples/sec | ETA 00:13:13\n",
      "2021-05-22 13:08:00 [INFO]\t[TRAIN] epoch=8, iter=2450/3200, loss=0.8014, lr=0.000128, batch_cost=1.0436, reader_cost=0.00024, ips=1.9165 samples/sec | ETA 00:13:02\n",
      "2021-05-22 13:08:10 [INFO]\t[TRAIN] epoch=8, iter=2460/3200, loss=0.8094, lr=0.000128, batch_cost=1.0441, reader_cost=0.00022, ips=1.9156 samples/sec | ETA 00:12:52\n",
      "2021-05-22 13:08:20 [INFO]\t[TRAIN] epoch=8, iter=2470/3200, loss=0.7685, lr=0.000127, batch_cost=1.0443, reader_cost=0.00020, ips=1.9151 samples/sec | ETA 00:12:42\n",
      "2021-05-22 13:08:31 [INFO]\t[TRAIN] epoch=8, iter=2480/3200, loss=0.8399, lr=0.000126, batch_cost=1.0454, reader_cost=0.00019, ips=1.9132 samples/sec | ETA 00:12:32\n",
      "2021-05-22 13:08:41 [INFO]\t[TRAIN] epoch=8, iter=2490/3200, loss=0.7899, lr=0.000125, batch_cost=1.0459, reader_cost=0.00024, ips=1.9122 samples/sec | ETA 00:12:22\n",
      "2021-05-22 13:08:52 [INFO]\t[TRAIN] epoch=8, iter=2500/3200, loss=0.8883, lr=0.000125, batch_cost=1.0453, reader_cost=0.00018, ips=1.9133 samples/sec | ETA 00:12:11\n",
      "2021-05-22 13:09:02 [INFO]\t[TRAIN] epoch=8, iter=2510/3200, loss=0.9017, lr=0.000124, batch_cost=1.0439, reader_cost=0.00018, ips=1.9158 samples/sec | ETA 00:12:00\n",
      "2021-05-22 13:09:13 [INFO]\t[TRAIN] epoch=8, iter=2520/3200, loss=1.0211, lr=0.000123, batch_cost=1.0443, reader_cost=0.00016, ips=1.9151 samples/sec | ETA 00:11:50\n",
      "2021-05-22 13:09:23 [INFO]\t[TRAIN] epoch=8, iter=2530/3200, loss=0.7776, lr=0.000123, batch_cost=1.0477, reader_cost=0.00018, ips=1.9089 samples/sec | ETA 00:11:41\n",
      "2021-05-22 13:09:34 [INFO]\t[TRAIN] epoch=8, iter=2540/3200, loss=0.7348, lr=0.000122, batch_cost=1.0438, reader_cost=0.00020, ips=1.9161 samples/sec | ETA 00:11:28\n",
      "2021-05-22 13:09:44 [INFO]\t[TRAIN] epoch=8, iter=2550/3200, loss=0.7425, lr=0.000121, batch_cost=1.0435, reader_cost=0.00025, ips=1.9167 samples/sec | ETA 00:11:18\n",
      "2021-05-22 13:09:55 [INFO]\t[TRAIN] epoch=8, iter=2560/3200, loss=0.8563, lr=0.000121, batch_cost=1.0455, reader_cost=0.00021, ips=1.9130 samples/sec | ETA 00:11:09\n",
      "2021-05-22 13:09:55 [INFO]\tStart evaluating (total_samples=160, total_iters=160)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 51s 322ms/step - batch_cost: 0.1607 - reader cost: 0.140\n",
      "160/160 [==============================] - 51s 322ms/step - batch_cost: 0.1602 - reader cost: 0.1402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-22 13:10:46 [INFO]\t[EVAL] #Images=160 mIoU=0.4941 Acc=0.9881 Kappa=0.0000 \n",
      "2021-05-22 13:10:46 [INFO]\t[EVAL] Class IoU: \n",
      "[0.     0.9881]\n",
      "2021-05-22 13:10:46 [INFO]\t[EVAL] Class Acc: \n",
      "[0.     0.9881]\n",
      "2021-05-22 13:10:46 [INFO]\t[EVAL] #Images=160 mIoU=0.6860 Acc=0.9528 Kappa=0.5707 \n",
      "2021-05-22 13:10:46 [INFO]\t[EVAL] Class IoU: \n",
      "[0.4209 0.9512]\n",
      "2021-05-22 13:10:46 [INFO]\t[EVAL] Class Acc: \n",
      "[0.9111 0.9545]\n",
      "2021-05-22 13:10:49 [INFO]\t[EVAL] The model with the best validation mIoU (0.7466) was saved at iter 1920.\n",
      "2021-05-22 13:11:00 [INFO]\t[TRAIN] epoch=9, iter=2570/3200, loss=0.8654, lr=0.000120, batch_cost=1.1041, reader_cost=0.06131, ips=1.8115 samples/sec | ETA 00:11:35\n",
      "2021-05-22 13:11:11 [INFO]\t[TRAIN] epoch=9, iter=2580/3200, loss=0.9962, lr=0.000119, batch_cost=1.0412, reader_cost=0.00027, ips=1.9209 samples/sec | ETA 00:10:45\n",
      "2021-05-22 13:11:21 [INFO]\t[TRAIN] epoch=9, iter=2590/3200, loss=0.8123, lr=0.000118, batch_cost=1.0413, reader_cost=0.00028, ips=1.9208 samples/sec | ETA 00:10:35\n",
      "2021-05-22 13:11:32 [INFO]\t[TRAIN] epoch=9, iter=2600/3200, loss=0.8489, lr=0.000118, batch_cost=1.0420, reader_cost=0.00022, ips=1.9195 samples/sec | ETA 00:10:25\n",
      "2021-05-22 13:11:42 [INFO]\t[TRAIN] epoch=9, iter=2610/3200, loss=0.8240, lr=0.000117, batch_cost=1.0427, reader_cost=0.00020, ips=1.9182 samples/sec | ETA 00:10:15\n",
      "2021-05-22 13:11:53 [INFO]\t[TRAIN] epoch=9, iter=2620/3200, loss=0.9836, lr=0.000116, batch_cost=1.0431, reader_cost=0.00019, ips=1.9174 samples/sec | ETA 00:10:04\n",
      "2021-05-22 13:12:03 [INFO]\t[TRAIN] epoch=9, iter=2630/3200, loss=0.9991, lr=0.000116, batch_cost=1.0419, reader_cost=0.00019, ips=1.9195 samples/sec | ETA 00:09:53\n",
      "2021-05-22 13:12:13 [INFO]\t[TRAIN] epoch=9, iter=2640/3200, loss=0.8352, lr=0.000115, batch_cost=1.0431, reader_cost=0.00022, ips=1.9174 samples/sec | ETA 00:09:44\n",
      "2021-05-22 13:12:24 [INFO]\t[TRAIN] epoch=9, iter=2650/3200, loss=0.7821, lr=0.000114, batch_cost=1.0425, reader_cost=0.00018, ips=1.9185 samples/sec | ETA 00:09:33\n",
      "2021-05-22 13:12:34 [INFO]\t[TRAIN] epoch=9, iter=2660/3200, loss=0.8321, lr=0.000114, batch_cost=1.0423, reader_cost=0.00018, ips=1.9188 samples/sec | ETA 00:09:22\n",
      "2021-05-22 13:12:45 [INFO]\t[TRAIN] epoch=9, iter=2670/3200, loss=0.9532, lr=0.000113, batch_cost=1.0435, reader_cost=0.00022, ips=1.9167 samples/sec | ETA 00:09:13\n",
      "2021-05-22 13:12:55 [INFO]\t[TRAIN] epoch=9, iter=2680/3200, loss=0.7879, lr=0.000112, batch_cost=1.0431, reader_cost=0.00023, ips=1.9173 samples/sec | ETA 00:09:02\n",
      "2021-05-22 13:13:06 [INFO]\t[TRAIN] epoch=9, iter=2690/3200, loss=0.8001, lr=0.000111, batch_cost=1.0522, reader_cost=0.00022, ips=1.9008 samples/sec | ETA 00:08:56\n",
      "2021-05-22 13:13:16 [INFO]\t[TRAIN] epoch=9, iter=2700/3200, loss=0.9835, lr=0.000111, batch_cost=1.0427, reader_cost=0.00020, ips=1.9181 samples/sec | ETA 00:08:41\n",
      "2021-05-22 13:13:26 [INFO]\t[TRAIN] epoch=9, iter=2710/3200, loss=0.7556, lr=0.000110, batch_cost=1.0431, reader_cost=0.00018, ips=1.9174 samples/sec | ETA 00:08:31\n",
      "2021-05-22 13:13:37 [INFO]\t[TRAIN] epoch=9, iter=2720/3200, loss=0.9145, lr=0.000109, batch_cost=1.0433, reader_cost=0.00017, ips=1.9171 samples/sec | ETA 00:08:20\n",
      "2021-05-22 13:13:47 [INFO]\t[TRAIN] epoch=9, iter=2730/3200, loss=0.8416, lr=0.000109, batch_cost=1.0438, reader_cost=0.00022, ips=1.9161 samples/sec | ETA 00:08:10\n",
      "2021-05-22 13:13:58 [INFO]\t[TRAIN] epoch=9, iter=2740/3200, loss=0.7813, lr=0.000108, batch_cost=1.0436, reader_cost=0.00017, ips=1.9165 samples/sec | ETA 00:08:00\n",
      "2021-05-22 13:14:08 [INFO]\t[TRAIN] epoch=9, iter=2750/3200, loss=0.7676, lr=0.000107, batch_cost=1.0443, reader_cost=0.00019, ips=1.9152 samples/sec | ETA 00:07:49\n",
      "2021-05-22 13:14:19 [INFO]\t[TRAIN] epoch=9, iter=2760/3200, loss=0.7639, lr=0.000106, batch_cost=1.0437, reader_cost=0.00020, ips=1.9163 samples/sec | ETA 00:07:39\n",
      "2021-05-22 13:14:29 [INFO]\t[TRAIN] epoch=9, iter=2770/3200, loss=0.8097, lr=0.000106, batch_cost=1.0431, reader_cost=0.00019, ips=1.9173 samples/sec | ETA 00:07:28\n",
      "2021-05-22 13:14:40 [INFO]\t[TRAIN] epoch=9, iter=2780/3200, loss=0.8102, lr=0.000105, batch_cost=1.0435, reader_cost=0.00018, ips=1.9166 samples/sec | ETA 00:07:18\n",
      "2021-05-22 13:14:50 [INFO]\t[TRAIN] epoch=9, iter=2790/3200, loss=1.0659, lr=0.000104, batch_cost=1.0452, reader_cost=0.00022, ips=1.9135 samples/sec | ETA 00:07:08\n",
      "2021-05-22 13:15:00 [INFO]\t[TRAIN] epoch=9, iter=2800/3200, loss=0.7622, lr=0.000104, batch_cost=1.0441, reader_cost=0.00022, ips=1.9156 samples/sec | ETA 00:06:57\n",
      "2021-05-22 13:15:11 [INFO]\t[TRAIN] epoch=9, iter=2810/3200, loss=0.9610, lr=0.000103, batch_cost=1.0447, reader_cost=0.00020, ips=1.9145 samples/sec | ETA 00:06:47\n",
      "2021-05-22 13:15:21 [INFO]\t[TRAIN] epoch=9, iter=2820/3200, loss=0.7916, lr=0.000102, batch_cost=1.0450, reader_cost=0.00018, ips=1.9139 samples/sec | ETA 00:06:37\n",
      "2021-05-22 13:15:32 [INFO]\t[TRAIN] epoch=9, iter=2830/3200, loss=0.7692, lr=0.000102, batch_cost=1.0456, reader_cost=0.00018, ips=1.9128 samples/sec | ETA 00:06:26\n",
      "2021-05-22 13:15:42 [INFO]\t[TRAIN] epoch=9, iter=2840/3200, loss=0.8527, lr=0.000101, batch_cost=1.0439, reader_cost=0.00017, ips=1.9158 samples/sec | ETA 00:06:15\n",
      "2021-05-22 13:15:53 [INFO]\t[TRAIN] epoch=9, iter=2850/3200, loss=0.9402, lr=0.000100, batch_cost=1.0441, reader_cost=0.00018, ips=1.9155 samples/sec | ETA 00:06:05\n",
      "2021-05-22 13:16:03 [INFO]\t[TRAIN] epoch=9, iter=2860/3200, loss=0.7475, lr=0.000099, batch_cost=1.0453, reader_cost=0.00023, ips=1.9134 samples/sec | ETA 00:05:55\n",
      "2021-05-22 13:16:14 [INFO]\t[TRAIN] epoch=9, iter=2870/3200, loss=0.8195, lr=0.000099, batch_cost=1.0440, reader_cost=0.00019, ips=1.9157 samples/sec | ETA 00:05:44\n",
      "2021-05-22 13:16:24 [INFO]\t[TRAIN] epoch=9, iter=2880/3200, loss=0.7524, lr=0.000098, batch_cost=1.0447, reader_cost=0.00017, ips=1.9144 samples/sec | ETA 00:05:34\n",
      "2021-05-22 13:16:24 [INFO]\tStart evaluating (total_samples=160, total_iters=160)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 51s 321ms/step - batch_cost: 0.1602 - reader cost: 0.140\n",
      "160/160 [==============================] - 51s 321ms/step - batch_cost: 0.1597 - reader cost: 0.1395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-22 13:17:15 [INFO]\t[EVAL] #Images=160 mIoU=0.4941 Acc=0.9881 Kappa=0.0000 \n",
      "2021-05-22 13:17:15 [INFO]\t[EVAL] Class IoU: \n",
      "[0.     0.9881]\n",
      "2021-05-22 13:17:15 [INFO]\t[EVAL] Class Acc: \n",
      "[0.     0.9881]\n",
      "2021-05-22 13:17:15 [INFO]\t[EVAL] #Images=160 mIoU=0.7337 Acc=0.9589 Kappa=0.6550 \n",
      "2021-05-22 13:17:15 [INFO]\t[EVAL] Class IoU: \n",
      "[0.5103 0.957 ]\n",
      "2021-05-22 13:17:15 [INFO]\t[EVAL] Class Acc: \n",
      "[0.8799 0.9629]\n",
      "2021-05-22 13:17:19 [INFO]\t[EVAL] The model with the best validation mIoU (0.7466) was saved at iter 1920.\n",
      "2021-05-22 13:17:30 [INFO]\t[TRAIN] epoch=10, iter=2890/3200, loss=0.7126, lr=0.000097, batch_cost=1.1139, reader_cost=0.07020, ips=1.7955 samples/sec | ETA 00:05:45\n",
      "2021-05-22 13:17:40 [INFO]\t[TRAIN] epoch=10, iter=2900/3200, loss=1.1823, lr=0.000097, batch_cost=1.0512, reader_cost=0.00024, ips=1.9025 samples/sec | ETA 00:05:15\n",
      "2021-05-22 13:17:51 [INFO]\t[TRAIN] epoch=10, iter=2910/3200, loss=0.7078, lr=0.000096, batch_cost=1.0416, reader_cost=0.00021, ips=1.9202 samples/sec | ETA 00:05:02\n",
      "2021-05-22 13:18:01 [INFO]\t[TRAIN] epoch=10, iter=2920/3200, loss=0.8346, lr=0.000095, batch_cost=1.0420, reader_cost=0.00019, ips=1.9193 samples/sec | ETA 00:04:51\n",
      "2021-05-22 13:18:12 [INFO]\t[TRAIN] epoch=10, iter=2930/3200, loss=0.7354, lr=0.000095, batch_cost=1.0426, reader_cost=0.00018, ips=1.9183 samples/sec | ETA 00:04:41\n",
      "2021-05-22 13:18:22 [INFO]\t[TRAIN] epoch=10, iter=2940/3200, loss=0.7870, lr=0.000094, batch_cost=1.0418, reader_cost=0.00019, ips=1.9198 samples/sec | ETA 00:04:30\n",
      "2021-05-22 13:18:32 [INFO]\t[TRAIN] epoch=10, iter=2950/3200, loss=0.7740, lr=0.000093, batch_cost=1.0429, reader_cost=0.00019, ips=1.9177 samples/sec | ETA 00:04:20\n",
      "2021-05-22 13:18:43 [INFO]\t[TRAIN] epoch=10, iter=2960/3200, loss=0.7826, lr=0.000092, batch_cost=1.0431, reader_cost=0.00018, ips=1.9173 samples/sec | ETA 00:04:10\n",
      "2021-05-22 13:18:53 [INFO]\t[TRAIN] epoch=10, iter=2970/3200, loss=0.8240, lr=0.000092, batch_cost=1.0428, reader_cost=0.00018, ips=1.9179 samples/sec | ETA 00:03:59\n",
      "2021-05-22 13:19:04 [INFO]\t[TRAIN] epoch=10, iter=2980/3200, loss=0.8049, lr=0.000091, batch_cost=1.0432, reader_cost=0.00019, ips=1.9173 samples/sec | ETA 00:03:49\n",
      "2021-05-22 13:19:14 [INFO]\t[TRAIN] epoch=10, iter=2990/3200, loss=0.7240, lr=0.000090, batch_cost=1.0441, reader_cost=0.00020, ips=1.9156 samples/sec | ETA 00:03:39\n",
      "2021-05-22 13:19:25 [INFO]\t[TRAIN] epoch=10, iter=3000/3200, loss=0.9480, lr=0.000090, batch_cost=1.0482, reader_cost=0.00018, ips=1.9080 samples/sec | ETA 00:03:29\n",
      "2021-05-22 13:19:35 [INFO]\t[TRAIN] epoch=10, iter=3010/3200, loss=0.6964, lr=0.000089, batch_cost=1.0436, reader_cost=0.00021, ips=1.9165 samples/sec | ETA 00:03:18\n",
      "2021-05-22 13:19:46 [INFO]\t[TRAIN] epoch=10, iter=3020/3200, loss=0.7545, lr=0.000088, batch_cost=1.0443, reader_cost=0.00024, ips=1.9152 samples/sec | ETA 00:03:07\n",
      "2021-05-22 13:19:56 [INFO]\t[TRAIN] epoch=10, iter=3030/3200, loss=0.9316, lr=0.000088, batch_cost=1.0438, reader_cost=0.00021, ips=1.9161 samples/sec | ETA 00:02:57\n",
      "2021-05-22 13:20:06 [INFO]\t[TRAIN] epoch=10, iter=3040/3200, loss=0.7853, lr=0.000087, batch_cost=1.0444, reader_cost=0.00020, ips=1.9150 samples/sec | ETA 00:02:47\n",
      "2021-05-22 13:20:17 [INFO]\t[TRAIN] epoch=10, iter=3050/3200, loss=0.8496, lr=0.000086, batch_cost=1.0447, reader_cost=0.00019, ips=1.9145 samples/sec | ETA 00:02:36\n",
      "2021-05-22 13:20:27 [INFO]\t[TRAIN] epoch=10, iter=3060/3200, loss=0.8017, lr=0.000085, batch_cost=1.0540, reader_cost=0.00019, ips=1.8976 samples/sec | ETA 00:02:27\n",
      "2021-05-22 13:20:38 [INFO]\t[TRAIN] epoch=10, iter=3070/3200, loss=0.8624, lr=0.000085, batch_cost=1.0445, reader_cost=0.00020, ips=1.9147 samples/sec | ETA 00:02:15\n",
      "2021-05-22 13:20:48 [INFO]\t[TRAIN] epoch=10, iter=3080/3200, loss=0.8692, lr=0.000084, batch_cost=1.0458, reader_cost=0.00021, ips=1.9125 samples/sec | ETA 00:02:05\n",
      "2021-05-22 13:20:59 [INFO]\t[TRAIN] epoch=10, iter=3090/3200, loss=1.1344, lr=0.000083, batch_cost=1.0459, reader_cost=0.00023, ips=1.9122 samples/sec | ETA 00:01:55\n",
      "2021-05-22 13:21:09 [INFO]\t[TRAIN] epoch=10, iter=3100/3200, loss=0.7661, lr=0.000083, batch_cost=1.0457, reader_cost=0.00020, ips=1.9126 samples/sec | ETA 00:01:44\n",
      "2021-05-22 13:21:20 [INFO]\t[TRAIN] epoch=10, iter=3110/3200, loss=0.7916, lr=0.000082, batch_cost=1.0452, reader_cost=0.00020, ips=1.9135 samples/sec | ETA 00:01:34\n",
      "2021-05-22 13:21:30 [INFO]\t[TRAIN] epoch=10, iter=3120/3200, loss=0.7246, lr=0.000081, batch_cost=1.0452, reader_cost=0.00019, ips=1.9135 samples/sec | ETA 00:01:23\n",
      "2021-05-22 13:21:41 [INFO]\t[TRAIN] epoch=10, iter=3130/3200, loss=0.8630, lr=0.000081, batch_cost=1.0448, reader_cost=0.00021, ips=1.9142 samples/sec | ETA 00:01:13\n",
      "2021-05-22 13:21:51 [INFO]\t[TRAIN] epoch=10, iter=3140/3200, loss=0.7551, lr=0.000080, batch_cost=1.0451, reader_cost=0.00023, ips=1.9137 samples/sec | ETA 00:01:02\n",
      "2021-05-22 13:22:02 [INFO]\t[TRAIN] epoch=10, iter=3150/3200, loss=0.8458, lr=0.000079, batch_cost=1.0450, reader_cost=0.00026, ips=1.9138 samples/sec | ETA 00:00:52\n",
      "2021-05-22 13:22:12 [INFO]\t[TRAIN] epoch=10, iter=3160/3200, loss=0.9107, lr=0.000078, batch_cost=1.0440, reader_cost=0.00020, ips=1.9156 samples/sec | ETA 00:00:41\n",
      "2021-05-22 13:22:22 [INFO]\t[TRAIN] epoch=10, iter=3170/3200, loss=0.8488, lr=0.000078, batch_cost=1.0443, reader_cost=0.00023, ips=1.9152 samples/sec | ETA 00:00:31\n",
      "2021-05-22 13:22:33 [INFO]\t[TRAIN] epoch=10, iter=3180/3200, loss=0.9099, lr=0.000077, batch_cost=1.0436, reader_cost=0.00021, ips=1.9164 samples/sec | ETA 00:00:20\n",
      "2021-05-22 13:22:43 [INFO]\t[TRAIN] epoch=10, iter=3190/3200, loss=0.9017, lr=0.000076, batch_cost=1.0435, reader_cost=0.00020, ips=1.9167 samples/sec | ETA 00:00:10\n",
      "2021-05-22 13:22:54 [INFO]\t[TRAIN] epoch=10, iter=3200/3200, loss=0.7902, lr=0.000076, batch_cost=1.0451, reader_cost=0.00019, ips=1.9136 samples/sec | ETA 00:00:00\n",
      "2021-05-22 13:22:54 [INFO]\tStart evaluating (total_samples=160, total_iters=160)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 51s 321ms/step - batch_cost: 0.1602 - reader cost: 0.14\n",
      "160/160 [==============================] - 51s 321ms/step - batch_cost: 0.1597 - reader cost: 0.1398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-22 13:23:45 [INFO]\t[EVAL] #Images=160 mIoU=0.4941 Acc=0.9881 Kappa=0.0000 \n",
      "2021-05-22 13:23:45 [INFO]\t[EVAL] Class IoU: \n",
      "[0.     0.9881]\n",
      "2021-05-22 13:23:45 [INFO]\t[EVAL] Class Acc: \n",
      "[0.     0.9881]\n",
      "2021-05-22 13:23:45 [INFO]\t[EVAL] #Images=160 mIoU=0.7285 Acc=0.9579 Kappa=0.6464 \n",
      "2021-05-22 13:23:45 [INFO]\t[EVAL] Class IoU: \n",
      "[0.501  0.9561]\n",
      "2021-05-22 13:23:45 [INFO]\t[EVAL] Class Acc: \n",
      "[0.8718 0.9623]\n",
      "2021-05-22 13:23:48 [INFO]\t[EVAL] The model with the best validation mIoU (0.7466) was saved at iter 1920.\n",
      "<class 'paddle.nn.layer.conv.Conv2D'>'s flops has been counted\n",
      "Customize Function has been applied to <class 'paddle.nn.layer.norm.SyncBatchNorm'>\n",
      "Cannot find suitable count function for <class 'paddle.nn.layer.pooling.MaxPool2D'>. Treat it as zero FLOPs.\n",
      "Cannot find suitable count function for <class 'paddle.nn.layer.common.Upsample'>. Treat it as zero FLOPs.\n",
      "<class 'paddle.nn.layer.norm.BatchNorm2D'>'s flops has been counted\n",
      "<class 'paddle.nn.layer.activation.ReLU'>'s flops has been counted\n",
      "Cannot find suitable count function for <class 'paddle.nn.layer.activation.Sigmoid'>. Treat it as zero FLOPs.\n",
      "<class 'paddle.nn.layer.common.Linear'>'s flops has been counted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:143: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:238: UserWarning: The dtype of left and right variables are not the same, left dtype is VarType.FP32, but right dtype is VarType.INT32, the right dtype will convert to VarType.FP32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Flops: 557239631872     Total Params: 22782896\n"
     ]
    }
   ],
   "source": [
    "from paddleseg.core import train\r\n",
    "\r\n",
    "train(\r\n",
    "    model=model,\r\n",
    "    train_dataset=train_dataset,\r\n",
    "    val_dataset=val_dataset,\r\n",
    "    optimizer=optimizer,\r\n",
    "    save_dir='save_output',\r\n",
    "    iters=iters,\r\n",
    "    batch_size=batch_size,\r\n",
    "    save_interval=int(iters/10),\r\n",
    "    log_iters=10,\r\n",
    "    num_workers=0,\r\n",
    "    losses=losses,\r\n",
    "    use_vdl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:54<00:00,  2.30it/s]\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "from paddleseg.models import DBAttentionUNet\r\n",
    "import paddleseg.transforms as T\r\n",
    "from paddleseg.core import infer\r\n",
    "import os\r\n",
    "import cv2\r\n",
    "from tqdm import tqdm\r\n",
    "from PIL import Image\r\n",
    "import numpy as np\r\n",
    "import patta as tta\r\n",
    "\r\n",
    "def nn_infer(model, imgs_path, is_tta=True):\r\n",
    "    if not os.path.exists('Lesion_Segmentation'):\r\n",
    "        os.mkdir('Lesion_Segmentation')\r\n",
    "    if not os.path.exists('Lesion_Segmentation/Atrophy'):\r\n",
    "        os.mkdir('Lesion_Segmentation/Atrophy')\r\n",
    "    if not os.path.exists('Lesion_Segmentation/Detachment'):\r\n",
    "        os.mkdir('Lesion_Segmentation/Detachment')\r\n",
    "    # 预测结果\r\n",
    "    transforms = T.Compose([\r\n",
    "        T.Resize(target_size=(1120, 1120)),\r\n",
    "        T.Normalize()\r\n",
    "    ])\r\n",
    "    # 循环预测和保存\r\n",
    "    for img_path in tqdm(imgs_path):\r\n",
    "        H, W, _ = np.asarray(Image.open(img_path)).shape\r\n",
    "        img, _ = transforms(img_path)  # 进行数据预处理\r\n",
    "        img = paddle.to_tensor(img[np.newaxis, :])  # C,H,W -> 1,C,H,W\r\n",
    "        # TTA\r\n",
    "        if is_tta == True:\r\n",
    "            tta_pres = paddle.zeros([1, 4, 1120, 1120])\r\n",
    "            for tta_transform in tta.aliases.flip_transform():\r\n",
    "                tta_img = tta_transform.augment_image(img)  # TTA_transforms\r\n",
    "                tta_pre = infer.inference(model, tta_img)  # 预测\r\n",
    "                deaug_pre = tta_transform.deaugment_mask(tta_pre)\r\n",
    "                tta_pres += deaug_pre\r\n",
    "            pre = tta_pres / 5.\r\n",
    "        else:\r\n",
    "            pre = infer.inference(model, img)  # 预测\r\n",
    "        clas_1 = paddle.argmax(pre[0]).numpy()[0]\r\n",
    "        clas_2 = paddle.argmax(pre[1]).numpy()[0]\r\n",
    "        # if clas_1 == 1:\r\n",
    "        #     pred_1 = pre[2].numpy().reshape((1120, 1120)).astype('uint8') * 255\r\n",
    "        # else:\r\n",
    "        #     pred_1 = np.ones((1120, 1120)).astype('uint8') * 255\r\n",
    "        pred_1 = pre[2].numpy().reshape((1120, 1120)).astype('uint8') * 255\r\n",
    "        # if clas_2 == 1:\r\n",
    "        #     pred_2 = pre[3].numpy().reshape((1120, 1120)).astype('uint8') * 255\r\n",
    "        # else:\r\n",
    "        #     pred_2 = np.ones((1120, 1120)).astype('uint8') * 255\r\n",
    "        pred_2 = pre[3].numpy().reshape((1120, 1120)).astype('uint8') * 255\r\n",
    "        pred_1 = cv2.resize(pred_1, (W, H), interpolation=cv2.INTER_NEAREST)\r\n",
    "        pred_1[:, 2100:] = 255\r\n",
    "        pred_2 = cv2.resize(pred_2, (W, H), interpolation=cv2.INTER_NEAREST)\r\n",
    "        pil_img_1 = Image.fromarray(pred_1)\r\n",
    "        pil_img_1.save(os.path.join('Lesion_Segmentation/Detachment', img_path.split('/')[-1].replace('jpg', 'png')), 'png')\r\n",
    "        pil_img_2 = Image.fromarray(pred_2)\r\n",
    "        pil_img_2.save(os.path.join('Lesion_Segmentation/Atrophy', img_path.split('/')[-1].replace('jpg', 'png')), 'png')\r\n",
    "\r\n",
    "# 网络准备\r\n",
    "model_path='save_output/best_model/model.pdparams'\r\n",
    "model = DBAttentionUNet(num_classes=2, pretrained=None)\r\n",
    "params = paddle.load(model_path)\r\n",
    "model.set_dict(params)\r\n",
    "model.eval()\r\n",
    "# 预测文件\r\n",
    "set_path = 'dataset/PALM-Testing400-Images'\r\n",
    "names = os.listdir(set_path)\r\n",
    "imgs_path = []\r\n",
    "for name in names:\r\n",
    "    imgs_path.append(os.path.join(set_path, name))\r\n",
    "# 预测\r\n",
    "nn_infer(model, imgs_path, is_tta=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
